{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from wordcloud import WordCloud as wc   # not needed\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "import sklearn\n",
    "import string\n",
    "import scipy\n",
    "import numpy\n",
    "import nltk\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.0.2\n",
      "sklearn: 0.20.1\n",
      "scipy: 1.1.0\n",
      "seaborn: 0.9.0\n",
      "pandas: 0.23.4\n",
      "numpy: 1.15.4\n",
      "Python: 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# printing versions of the important packages\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('Python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I start Collection Data by reading training and testing datasets \n",
    "# into Pandas DataFrames.\n",
    "\n",
    "train_large = pd.read_csv('Data&Images/train.csv')\n",
    "test_large = pd.read_csv('Data&Images/test.csv')\n",
    "\n",
    "train = train_large[:1500]\n",
    "test = test_large[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top 5 records of training dataset\n",
    "train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top 5 records of testing dataset\n",
    "test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 3 columns):\n",
      "qid              1500 non-null object\n",
      "question_text    1500 non-null object\n",
      "target           1500 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Find the type of features in Quora dataset\n",
    "# i.e get a quick statistics\n",
    "\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      "qid              100 non-null object\n",
      "question_text    100 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test.info())  # see carefully the last value is -> None. \n",
    "                    # indicating that there are no \"Null\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (1500, 3)\n",
      "Shape of test: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# shape for train and test\n",
    "print('Shape of train:',train.shape)\n",
    "print('Shape of test:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many NA elements in every column!!\n",
    "# Good news, it is Zero!\n",
    "# To check out how many null info are on the dataset, we can use isnull().sum().\n",
    "# recall from info() -> we found that it has zero Nulls. \n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "# data is infact clean and ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Droping (1500, 3)\n",
      "After Droping (1500, 3)\n"
     ]
    }
   ],
   "source": [
    "# in case , their were NA or None values in any row then we would drop the row.\n",
    "\n",
    "# remove rows that have NA's\n",
    "print('Before Droping',train.shape)\n",
    "train = train.dropna()\n",
    "print('After Droping',train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum of num_words in train 51\n",
      "min of num_words in train 3\n",
      "maximum of  num_words in test 34\n",
      "min of num_words in train 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Number of words in the text\n",
    "\n",
    "train[\"num_words\"] = train[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
    "print('maximum of num_words in train',train[\"num_words\"].max())\n",
    "print('min of num_words in train',train[\"num_words\"].min())\n",
    "print(\"maximum of  num_words in test\",test[\"num_words\"].max())\n",
    "print('min of num_words in train',test[\"num_words\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum of num_unique_words in train 44\n",
      "maximum of num_unique_words in test 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Number of unique words in the text\n",
    "train[\"num_unique_words\"] = train[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words\"] = test[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "print('maximum of num_unique_words in train',train[\"num_unique_words\"].max())\n",
    "\n",
    "print(\"maximum of num_unique_words in test\",test[\"num_unique_words\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum of num_stopwords in train 29\n",
      "maximum of num_stopwords in test 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Number of stopwords in the text\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "train[\"num_stopwords\"] = train[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test[\"num_stopwords\"] = test[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "print('maximum of num_stopwords in train',train[\"num_stopwords\"].max())\n",
    "print(\"maximum of num_stopwords in test\",test[\"num_stopwords\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum of num_punctuations in train 39\n",
      "maximum of num_punctuations in test 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train[\"num_punctuations\"] = train[\"question_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "test[\"num_punctuations\"] = test[\"question_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "print('maximum of num_punctuations in train',train[\"num_punctuations\"].max())\n",
    "print(\"maximum of num_punctuations in test\",test[\"num_punctuations\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets figure out how many unique target values exist.\n",
    "# like we expect : 0 -> sincere qns and 1 -> un-sincere qns\n",
    "\n",
    "# You see number of unique item for Target with command below:\n",
    "train_target = train['target'].values\n",
    "\n",
    "np.unique(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid                 86\n",
       "question_text       86\n",
       "target              86\n",
       "num_words           86\n",
       "num_unique_words    86\n",
       "num_stopwords       86\n",
       "num_punctuations    86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.where(train ['target']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of un-sincere qns is  0.05733333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"% of un-sincere qns is \", 86/1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising the imbalance in data set\n",
    "\n",
    "ax=sns.countplot(x='target',hue=\"target\", data=train  ,linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))\n",
    "plt.title('Is data set imbalance?');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>why do so many women become so rude and arroga...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>when should i apply for rv college of engineer...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>what is it really like to be a nurse practitio...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>who are entrepreneurs?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>is education really making good people nowadays?</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  0000163e3ea7c7a74cd7  why do so many women become so rude and arroga...   \n",
       "1  00002bd4fb5d505b9161  when should i apply for rv college of engineer...   \n",
       "2  00007756b4a147d2b0b3  what is it really like to be a nurse practitio...   \n",
       "3  000086e4b7e1c7146103                             who are entrepreneurs?   \n",
       "4  0000c4c3fbe8785a3090   is education really making good people nowadays?   \n",
       "\n",
       "   num_words  num_unique_words  num_stopwords  num_punctuations  \n",
       "0         21                19             11                 1  \n",
       "1         30                23             17                 2  \n",
       "2         10                10              6                 1  \n",
       "3          3                 3              2                 1  \n",
       "4          7                 7              1                 1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1: Change all the text to lower case. \n",
    "\n",
    "# This is required as python interprets 'quora' and 'QUORA' differently\n",
    "\n",
    "train['question_text'] = [entry.lower() for entry in train['question_text']]\n",
    "\n",
    "test['question_text'] = [entry.lower() for entry in test['question_text']]\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more imports for NLP\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>[why, do, so, many, women, become, so, rude, a...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>[when, should, i, apply, for, rv, college, of,...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>[what, is, it, really, like, to, be, a, nurse,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>[who, are, entrepreneurs, ?]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>[is, education, really, making, good, people, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  0000163e3ea7c7a74cd7  [why, do, so, many, women, become, so, rude, a...   \n",
       "1  00002bd4fb5d505b9161  [when, should, i, apply, for, rv, college, of,...   \n",
       "2  00007756b4a147d2b0b3  [what, is, it, really, like, to, be, a, nurse,...   \n",
       "3  000086e4b7e1c7146103                       [who, are, entrepreneurs, ?]   \n",
       "4  0000c4c3fbe8785a3090  [is, education, really, making, good, people, ...   \n",
       "\n",
       "   num_words  num_unique_words  num_stopwords  num_punctuations  \n",
       "0         21                19             11                 1  \n",
       "1         30                23             17                 2  \n",
       "2         10                10              6                 1  \n",
       "3          3                 3              2                 1  \n",
       "4          7                 7              1                 1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2 : Tokenization : In this each entry in the corpus will be broken \n",
    "#                         into set of words\n",
    "\n",
    "\n",
    "train['question_text']= [word_tokenize(entry) for entry in train['question_text']]\n",
    "\n",
    "test['question_text']= [word_tokenize(entry) for entry in test['question_text']]\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "# This is used to reproduce the same result every time \n",
    "# if the script is kept consistent otherwise each run \n",
    "# will produce different results. The seed can be set to any number.\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    qid                                      question_text  \\\n",
      "0  00002165364db923c7e6  [how, did, quebec, nationalists, see, their, p...   \n",
      "1  000032939017120e6e44  [do, you, have, an, adopted, dog, ,, how, woul...   \n",
      "2  0000412ca6e4628ce2cf  [why, does, velocity, affect, time, ?, does, v...   \n",
      "3  000042bf85aa498cd78e  [how, did, otto, von, guericke, used, the, mag...   \n",
      "4  0000455dfa3e01eae3af  [can, i, convert, montra, helicon, d, to, a, m...   \n",
      "\n",
      "   target  num_words  num_unique_words  num_stopwords  num_punctuations  \\\n",
      "0       0         13                13              7                 1   \n",
      "1       0         16                15              9                 2   \n",
      "2       0         10                 8              3                 2   \n",
      "3       0          9                 9              3                 1   \n",
      "4       0         15                15              8                 1   \n",
      "\n",
      "                                 question_text_final  \n",
      "0  ['quebec', 'nationalist', 'see', 'province', '...  \n",
      "1  ['adopt', 'dog', 'would', 'encourage', 'people...  \n",
      "2  ['velocity', 'affect', 'time', 'velocity', 'af...  \n",
      "3  ['otto', 'von', 'guericke', 'use', 'magdeburg'...  \n",
      "4  ['convert', 'montra', 'helicon', 'mountain', '...  \n"
     ]
    }
   ],
   "source": [
    "# step 3, 4 and 5\n",
    "# Remove Stop words and Numeric data \n",
    "# and perfom Word Stemming/Lemmenting.\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb\n",
    "# or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "# the tag_map would map any tag to 'N' (Noun) except\n",
    "# Adjective to J, Verb -> v, Adverb -> R\n",
    "# that means if you get a Pronoun then it would still be mapped to Noun\n",
    "\n",
    "\n",
    "for index,entry in enumerate(train['question_text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    \n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    \n",
    "    # pos_tag function below will provide the 'tag' \n",
    "    # i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only \n",
    "        # alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "            \n",
    "    # The final processed set of words for each iteration will be stored \n",
    "    # in 'question_text_final'\n",
    "    #print(type(Final_words))\n",
    "    temp = pd.DataFrame(Final_words)\n",
    "    train.append(temp)\n",
    "\n",
    "    #train.loc[index,'question_text_final'] = str(Final_words)  \n",
    "    \n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\kamle\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    qid                                      question_text  \\\n",
      "0  0000163e3ea7c7a74cd7  [why, do, so, many, women, become, so, rude, a...   \n",
      "1  00002bd4fb5d505b9161  [when, should, i, apply, for, rv, college, of,...   \n",
      "2  00007756b4a147d2b0b3  [what, is, it, really, like, to, be, a, nurse,...   \n",
      "3  000086e4b7e1c7146103                       [who, are, entrepreneurs, ?]   \n",
      "4  0000c4c3fbe8785a3090  [is, education, really, making, good, people, ...   \n",
      "\n",
      "   num_words  num_unique_words  num_stopwords  num_punctuations  \\\n",
      "0         21                19             11                 1   \n",
      "1         30                23             17                 2   \n",
      "2         10                10              6                 1   \n",
      "3          3                 3              2                 1   \n",
      "4          7                 7              1                 1   \n",
      "\n",
      "                                 question_text_final  \n",
      "0  ['many', 'woman', 'become', 'rude', 'arrogant'...  \n",
      "1  ['apply', 'rv', 'college', 'engineering', 'bms...  \n",
      "2        ['really', 'like', 'nurse', 'practitioner']  \n",
      "3                                   ['entrepreneur']  \n",
      "4  ['education', 'really', 'make', 'good', 'peopl...  \n"
     ]
    }
   ],
   "source": [
    "# step 3, 4 and 5\n",
    "# Remove Stop words and Numeric data \n",
    "# and perfom Word Stemming/Lemmenting.\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb\n",
    "# or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "# the tag_map would map any tag to 'N' (Noun) except\n",
    "# Adjective to J, Verb -> v, Adverb -> R\n",
    "# that means if you get a Pronoun then it would still be mapped to Noun\n",
    "\n",
    "\n",
    "for index,entry in enumerate(test['question_text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words_test = []\n",
    "    \n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    \n",
    "    # pos_tag function below will provide the 'tag' \n",
    "    # i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only \n",
    "        # alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words_test.append(word_Final)\n",
    "            \n",
    "    # The final processed set of words for each iteration will be stored \n",
    "    # in 'question_text_final'\n",
    "    test.loc[index,'question_text_final'] = str(Final_words_test)    \n",
    "\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(train['question_text_final'])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(train['question_text_final'])\n",
    "\n",
    "Test_X_Tfidf = Tfidf_vect.transform(test['question_text_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quebec': 2722, 'nationalist': 2259, 'see': 2984, 'province': 2687, 'nation': 2256, 'adopt': 56, 'dog': 948, 'would': 3716, 'encourage': 1076, 'people': 2479, 'shop': 3035, 'velocity': 3570, 'affect': 67, 'time': 3402, 'space': 3144, 'geometry': 1402, 'otto': 2407, 'von': 3609, 'guericke': 1475, 'use': 3552, 'magdeburg': 2021, 'hemisphere': 1537, 'convert': 718, 'montra': 2198, 'helicon': 1532, 'mountain': 2216, 'bike': 361, 'change': 543, 'tyre': 3499, 'gaza': 1388, 'slowly': 3095, 'become': 326, 'auschwitz': 254, 'dachau': 798, 'treblinka': 3459, 'palestinian': 2433, 'quora': 2731, 'automatically': 262, 'ban': 293, 'conservative': 689, 'opinion': 2380, 'report': 2840, 'liberal': 1934, 'view': 3586, 'crazy': 748, 'wash': 3630, 'wipe': 3687, 'grocery': 1467, 'germ': 1405, 'everywhere': 1145, 'thing': 3382, 'dress': 974, 'moderately': 2179, 'different': 897, 'modestly': 2182, 'ever': 1138, 'phase': 2499, 'wherein': 3672, 'ignorant': 1625, 'love': 1997, 'completely': 664, 'disregard': 933, 'get': 1409, 'something': 3126, 'go': 1429, 'way': 3638, 'feel': 1234, 'temporarily': 3356, 'ease': 1005, 'say': 2953, 'feminism': 1239, 'calgary': 474, 'flame': 1279, 'found': 1326, 'dumbest': 986, 'yet': 3738, 'possibly': 2582, 'true': 3474, 'explanation': 1180, 'trump': 3475, 'elect': 1041, 'external': 1186, 'hard': 1506, 'disk': 930, 'well': 3658, 'data': 811, 'live': 1971, 'home': 1562, 'boyfriend': 418, 'progress': 2665, 'situation': 3080, 'know': 1845, 'bram': 421, 'fischer': 1272, 'rivonia': 2894, 'trial': 3463, 'difficult': 900, 'find': 1265, 'good': 1435, 'instructor': 1706, 'take': 3321, 'class': 593, 'near': 2269, 'lick': 1938, 'skin': 3086, 'corpse': 726, 'think': 3383, 'amazon': 124, 'house': 1578, 'approach': 183, 'manufacture': 2051, 'similar': 3061, 'tesla': 3368, 'business': 463, 'model': 2177, 'many': 2052, 'barony': 307, 'might': 2144, 'exist': 1167, 'within': 3694, 'county': 737, 'palatine': 2432, 'whether': 3673, 'girl': 1418, 'do': 944, 'sex': 3022, 'fast': 1218, 'learner': 1900, 'professional': 2655, 'career': 502, 'personal': 2494, 'life': 1940, 'united': 3528, 'state': 3194, 'large': 1877, 'dictatorship': 890, 'world': 3713, 'strange': 3223, 'phenomenon': 2502, 'witness': 3696, 'generate': 1394, 'area': 197, 'electronics': 1049, 'term': 3363, 'modern': 2180, 'physic': 2512, 'leave': 1906, 'friend': 1352, 'new': 2289, 'one': 2369, 'make': 2032, 'alexa': 96, 'trigger': 3465, 'event': 1136, 'browser': 447, 'two': 3494, 'democracy': 848, 'never': 2288, 'full': 1365, 'fledge': 1284, 'war': 3628, 'stop': 3218, 'top': 3420, 'cbse': 518, 'month': 2196, 'visit': 3594, 'mcleodganj': 2090, 'triund': 3468, 'trek': 3460, 'military': 2148, 'submarine': 3245, 'reduce': 2801, 'noise': 2307, 'achieve': 33, 'stealth': 3204, 'baby': 277, 'sweet': 3302, 'parent': 2442, 'dark': 809, 'light': 1946, 'remove': 2832, 'black': 382, 'head': 1519, 'nose': 2317, 'lightsabers': 1947, 'create': 749, 'individual': 1668, 'wielders': 3679, 'saber': 2929, 'unique': 3527, 'anyone': 169, 'still': 3213, 'visual': 3595, 'basic': 310, 'worth': 3715, 'learn': 1899, 'job': 1791, 'programmer': 2663, 'sykes': 3307, 'enterprise': 1094, 'clear': 599, 'relation': 2818, 'number': 2333, 'computational': 668, 'performance': 2486, 'requirement': 2847, 'fea': 1227, 'cfd': 534, 'analysis': 138, 'ansys': 162, 'solution': 3119, 'particular': 2449, 'package': 2422, 'isc': 1754, 'since': 3068, 'may': 2086, 'update': 3541, 'great': 1461, 'wit': 3692, 'mean': 2093, 'experience': 1176, 'work': 3707, 'realtor': 2781, 'wish': 3691, 'charge': 550, 'contact': 703, 'public': 2695, 'school': 2963, 'teacher': 3337, 'vacation': 3559, 'whenever': 3670, 'ask': 222, 'role': 2903, 'technology': 3343, 'resource': 2858, 'opt': 2385, 'jaypee': 1779, 'university': 3531, 'guna': 1484, 'mechanical': 2096, 'engineering': 1086, 'download': 964, 'microsoft': 2139, 'word': 3704, 'window': 3684, 'hungarian': 1592, 'need': 2273, 'buy': 465, 'car': 495, 'south': 3138, 'africa': 70, 'american': 128, 'someone': 3125, 'enjoy': 1089, 'harry': 1510, 'potter': 2588, 'order': 2392, 'phoenix': 2507, 'movie': 2219, 'least': 1904, 'book': 406, 'write': 3721, 'style': 3241, 'resist': 2855, 'prince': 2629, 'charm': 552, 'linda': 1953, 'kage': 1810, 'mother': 2209, 'expect': 1173, 'memorize': 2113, 'usernames': 3556, 'password': 2457, 'responsible': 2863, 'college': 639, 'year': 3736, 'kid': 1828, 'fool': 1303, 'kill': 1830, 'bubble': 449, 'decide': 833, 'travel': 3456, 'portable': 2573, 'computer': 669, 'science': 2965, 'student': 3236, 'final': 1262, 'project': 2666, 'outside': 2412, 'rather': 2763, 'education': 1025, 'system': 3314, 'really': 2780, 'week': 3651, 'shorten': 3038, 'period': 2490, 'risk': 2892, 'calead': 473, 'leap': 1898, 'day': 818, 'rid': 2886, 'spleen': 3163, 'enlargement': 1091, 'machine': 2019, 'technique': 3342, 'extract': 1189, 'metadata': 2130, 'font': 1301, 'color': 642, 'size': 3082, 'indentation': 1661, 'alignment': 101, 'document': 947, 'file': 1256, 'integrate': 1710, 'web': 3644, 'application': 180, 'hitch': 1558, 'smith': 3101, 'asks': 223, 'dance': 806, 'much': 2225, 'india': 1662, 'act': 36, 'special': 3149, 'sport': 3166, 'like': 1948, 'dna': 943, 'rna': 2896, 'compare': 656, 'contrast': 710, 'break': 428, 'shoot': 3034, 'arm': 200, 'knife': 1842, 'happen': 1503, 'biography': 370, 'gianni': 1412, 'versace': 3578, 'extroverted': 1192, 'faster': 1219, 'process': 2644, 'expel': 1174, 'information': 1683, 'introvert': 1728, 'recognize': 2790, 'place': 2527, 'far': 1216, 'price': 2624, 'comparison': 657, 'websites': 3647, 'financial': 1264, 'service': 3014, 'rag': 2745, 'nift': 2299, 'bangalore': 297, 'bad': 285, 'review': 2875, 'bahubali': 287, 'imdb': 1638, 'swallow': 3298, 'listerine': 1965, 'dangerous': 807, 'theory': 3378, 'critical': 759, 'thinking': 3384, 'big': 360, 'problem': 2640, 'question': 2726, 'doubt': 962, 'come': 646, 'across': 35, 'try': 3479, 'choose': 575, 'paint': 2430, 'room': 2911, 'cheap': 553, 'flight': 1285, 'edinburgh': 1023, 'china': 569, 'chick': 562, 'send': 2995, 'picture': 2518, 'email': 1061, 'ebay': 1012, 'allow': 107, 'sale': 2938, 'wwii': 3727, 'purple': 2708, 'heart': 1527, 'medal': 2098, 'even': 1135, 'though': 3385, 'category': 516, 'specifically': 3153, 'characteristic': 548, 'define': 840, 'isovolumetric': 1759, 'relaxation': 2822, 'cybersecurity': 795, 'overseas': 2418, 'developer': 878, 'refer': 2802, 'standard': 3188, 'practice': 2596, 'internet': 1719, 'rely': 2826, 'everything': 1143, 'itc': 1766, 'levy': 1931, 'bank': 300, 'muhammed': 2228, 'provide': 2685, 'food': 1302, 'test': 3369, 'lab': 1861, 'certified': 533, 'ok': 2364, 'solo': 3118, 'whole': 3678, 'pretend': 2617, 'unwanted': 3539, 'owner': 2420, 'current': 786, 'youtube': 3744, 'account': 29, 'original': 2399, 'let': 1926, 'access': 25, 'anything': 170, 'archer': 195, 'character': 547, 'animate': 151, 'base': 308, 'celebrity': 521, 'best': 345, 'propose': 2676, 'without': 3695, 'annoy': 156, 'million': 2150, 'solar': 3114, 'power': 2591, 'recommended': 2793, 'game': 1379, 'engine': 1084, 'beginning': 333, 'python': 2715, 'teleological': 3350, 'pantheism': 2436, 'aircraft': 86, 'propulsion': 2677, 'country': 736, 'freedom': 1341, 'speech': 3154, 'par': 2438, 'lead': 1894, 'red': 2798, 'terror': 3366, 'ethiopia': 1129, 'pen': 2473, 'low': 1999, 'cost': 729, 'sort': 3134, 'trust': 3476, 'facebook': 1197, 'page': 2427, 'website': 3646, 'improve': 1651, 'piano': 2516, 'skill': 3084, 'keep': 1816, 'piece': 2519, 'effective': 1031, 'wear': 3642, 'insulin': 1707, 'pump': 2698, 'lot': 1990, 'nick': 2298, 'jonas': 1797, 'date': 814, 'selena': 2989, 'gomez': 1434, 'difference': 896, 'several': 3018, 'zero': 3747, 'miss': 2167, 'turkey': 3486, 'seperated': 3006, 'give': 1420, 'land': 1869, 'kurds': 1858, 'foreign': 1310, 'usa': 3549, 'future': 1375, 'sq': 3170, 'equal': 1107, 'sing': 3070, 'song': 3130, 'chronicle': 580, 'replace': 2838, 'supply': 3278, 'chain': 537, 'solve': 3120, 'sin': 3067, 'demerit': 847, 'excellence': 1157, 'academic': 20, 'pursuit': 2711, 'indian': 1663, 'melbourne': 2109, 'australia': 255, 'physicist': 2515, 'mathematician': 2079, 'scientist': 2967, 'philosopher': 2505, 'david': 817, 'deutsch': 874, 'old': 2366, 'scripture': 2973, 'eastern': 1008, 'culture': 781, 'appear': 178, 'lose': 1988, 'hate': 1517, 'mind': 2153, 'habit': 1489, 'procrastination': 2647, 'relationship': 2820, 'napoleon': 2250, 'ali': 98, 'pasha': 2455, 'tepelene': 3362, 'presynaptic': 2616, 'neuron': 2284, 'narcissist': 2251, 'punish': 2700, 'child': 564, 'back': 280, 'start': 3192, 'freelance': 1342, 'finish': 1266, 'udacity': 3502, 'android': 144, 'nanodegree': 2249, 'reason': 2782, 'bitcoin': 379, 'long': 1984, 'journey': 1800, 'support': 3279, 'choice': 574, 'mandatory': 2040, 'sentencing': 3002, 'criminal': 756, 'vote': 3610, 'republican': 2843, 'add': 47, 'thrice': 3390, 'rational': 2764, 'four': 1329, 'movement': 2218, 'symphony': 3310, 'typically': 3496, 'form': 1317, 'second': 2980, 'various': 3563, 'stock': 3215, 'exchange': 1160, 'gay': 1387, 'boy': 417, 'cousin': 742, 'sexy': 3024, 'dont': 957, 'hot': 1575, 'want': 3627, 'race': 2738, 'small': 3098, 'penis': 2478, 'architecture': 196, 'microarchitecture': 2137, 'instruction': 1705, 'set': 3015, 'isa': 1753, 'iphone': 1744, 'user': 3555, 'psychologically': 2690, 'trap': 3455, 'brand': 424, 'naming': 2248, 'avoid': 268, 'complain': 662, 'reasonable': 2783, 'feature': 1231, 'battery': 316, 'lack': 1863, 'flagship': 1278, 'semester': 2993, 'ontario': 2374, 'female': 1237, 'ugly': 3503, 'flour': 1289, 'homemade': 1563, 'chili': 568, 'advice': 63, 'accomplish': 26, 'overcome': 2413, 'extreme': 1190, 'fear': 1228, 'insect': 1693, 'bug': 453, 'example': 1156, 'durable': 988, 'glove': 1426, 'move': 2217, 'mile': 2146, 'towards': 3432, 'oppostie': 2382, 'direction': 912, 'distance': 935, 'apps': 189, 'maximum': 2084, 'header': 1520, 'dataset': 813, 'notice': 2320, 'print': 2633, 'first': 1271, 'anyway': 171, 'marry': 2068, 'woman': 3701, 'green': 1463, 'card': 497, 'company': 655, 'look': 1985, 'recruit': 2796, 'expat': 1172, 'nationality': 2261, 'candidate': 488, 'play': 2537, 'huge': 1584, 'transcranial': 3445, 'magnetic': 2024, 'stimulation': 3214, 'tm': 3409, 'increase': 1658, 'cognitive': 628, 'george': 1403, 'washington': 3631, 'free': 1340, 'slave': 3091, 'revolutionary': 2878, 'policy': 2553, 'embassy': 1062, 'deny': 853, 'citizen': 586, 'entry': 1100, 'party': 2452, 'energy': 1082, 'meter': 2132, 'periodically': 2491, 'stationery': 3197, 'office': 2358, 'vs': 3613, 'regular': 2810, 'genuine': 1401, 'aviation': 267, 'nonprofit': 2311, 'organization': 2396, 'treat': 3457, 'employee': 1070, 'badly': 286, 'procedure': 2642, 'invest': 1734, 'mutual': 2240, 'fund': 1371, 'osn': 2404, 'aesthetically': 66, 'please': 2540, 'shade': 3025, 'wise': 3690, 'calcutta': 472, 'prepare': 2605, 'cat': 512, 'politician': 2556, 'leech': 1909, 'sponsor': 3165, 'regime': 2807, 'north': 2315, 'korea': 1851, 'european': 1131, 'superior': 3274, 'fact': 1201, 'mid': 2141, 'century': 529, 'surpass': 3289, 'economy': 1020, 'cytoplasm': 796, 'build': 454, 'inside': 1694, 'lip': 1960, 'app': 174, 'multiple': 2229, 'programming': 2664, 'language': 1872, 'ide': 1617, 'neighborhood': 2277, 'chuncheon': 581, 'varanasi': 3562, 'wrongfully': 3724, 'jump': 1804, 'conclusion': 675, 'troubleshoot': 3472, 'printer': 2634, 'unfair': 3522, 'men': 2115, 'duty': 992, 'nsf': 2327, 'spinoff': 3160, 'nsfnet': 2328, 'help': 1534, 'sun': 3267, 'microsystem': 2140, 'tourist': 3430, 'drastically': 969, 'louisville': 1994, 'list': 1962, 'ranking': 2758, 'julius': 1802, 'caesar': 469, 'bring': 439, 'tyrannosaurus': 3498, 'rex': 2882, 'campaign': 479, 'frighten': 1357, 'celt': 524, 'submission': 3246, 'mercury': 2121, 'debilitate': 826, 'dasa': 810, 'simha': 3060, 'lagna': 1867, 'driver': 977, 'globalisation': 1423, 'high': 1545, 'emotional': 1066, 'intelligence': 1712, 'mainstream': 2028, 'fashion': 1217, 'cause': 517, 'force': 1307, 'magnet': 2023, 'nike': 2303, 'football': 1305, 'towel': 3433, 'win': 3683, 'anizara': 153, 'dragon': 967, 'ball': 290, 'super': 3271, 'anime': 152, 'episode': 1105, 'mystic': 2244, 'gohan': 1432, 'phone': 2508, 'fault': 1222, 'teen': 3345, 'daughter': 816, 'social': 3109, 'anxiety': 167, 'sunil': 3269, 'raju': 2751, 'absent': 12, 'today': 3410, 'appropriate': 184, 'manner': 2047, 'backing': 283, 'right': 2890, 'hypocritical': 1603, 'actually': 44, 'restrict': 2866, 'ability': 3, 'law': 1888, 'europeans': 1132, 'continue': 707, 'participate': 2448, 'arab': 193, 'destruction': 869, 'israel': 1760, 'jew': 1785, 'god': 1431, 'defend': 839, 'conversation': 716, 'php': 2510, 'framework': 1333, 'olx': 2367, 'forensic': 1312, 'psychologist': 2691, 'fortnite': 1320, 'lag': 1866, 'everytime': 1144, 'fight': 1253, 'neurotransmitter': 2285, 'puppy': 2704, 'hyper': 1601, 'jhargram': 1787, 'birbhum': 377, 'safe': 2932, 'winter': 3686, 'terrorist': 3367, 'discover': 925, 'instantly': 1702, 'paw': 2463, 'powerbank': 2592, 'average': 266, 'nfl': 2294, 'team': 3339, 'obtain': 2349, 'kicker': 1827, 'could': 732, 'consistently': 694, 'field': 1251, 'goal': 1430, 'yard': 3735, 'bowl': 414, 'earn': 1000, 'trading': 3437, 'derivative': 860, 'market': 2063, 'timing': 3403, 'html': 1583, 'cs': 772, 'lingayats': 1955, 'bury': 460, 'dead': 820, 'burn': 458, 'hindu': 1551, 'therapist': 3379, 'regard': 2805, 'mental': 2117, 'health': 1523, 'issue': 1763, 'remain': 2827, 'useful': 3554, 'honda': 1569, 'step': 3207, 'wgn': 3663, 'mileage': 2147, 'sign': 3052, 'singaporean': 3071, 'british': 442, 'australian': 256, 'accent': 22, 'pokmon': 2549, 'diamond': 889, 'mt': 2222, 'coronet': 723, 'merchant': 2120, 'track': 3435, 'smoke': 3103, 'cleave': 600, 'cigarette': 582, 'harmful': 1508, 'arnab': 207, 'goswami': 1442, 'able': 5, 'ignore': 1626, 'defamation': 838, 'case': 507, 'kejriwal': 1818, 'drag': 966, 'court': 739, 'everyday': 1141, 'institute': 1704, 'hadoop': 1492, 'course': 738, 'chandigarh': 542, 'clipboard': 607, 'rich': 2885, 'claim': 591, 'reservation': 2851, 'conscience': 687, 'instance': 1701, 'medieval': 2101, 'latin': 1884, 'text': 3370, 'later': 1883, 'translate': 3451, 'classical': 595, 'purpose': 2709, 'location': 1978, 'investment': 1738, 'gurgaon': 1485, 'husband': 1596, 'myopia': 2242, 'prevent': 2621, 'conceive': 672, 'possible': 2581, 'fighter': 1254, 'jet': 1784, 'airforce': 87, 'directory': 915, 'linux': 1959, 'megabites': 2107, 'interview': 1723, 'idea': 1618, 'shirt': 3032, 'suit': 3262, 'white': 3676, 'every': 1139, 'stammering': 3185, 'melodious': 2110, 'voice': 3603, 'five': 1274, 'type': 3495, 'foul': 1325, 'basetball': 309, 'canadian': 484, 'zealander': 3746, 'consider': 690, 'separate': 3004, 'speak': 3147, 'changer': 544, 'redmi': 2800, 'note': 2318, 'point': 2548, 'stay': 3200, 'frequency': 1348, 'division': 940, 'fdma': 1226, 'line': 1954, 'vb': 3566, 'explain': 1179, 'funeral': 1373, 'honey': 1570, 'singh': 3073, 'justin': 1808, 'bieber': 359, 'fall': 1208, 'floor': 1287, 'survive': 3291, 'laugh': 1886, 'loud': 1992, 'hold': 1559, 'license': 1937, 'mandated': 2039, 'reporter': 2841, 'emergency': 1063, 'occur': 2351, 'guru': 1486, 'granth': 1455, 'sahib': 2935, 'punjabi': 2703, 'ruin': 2920, 'man': 2034, 'falsly': 1210, 'accuse': 31, 'violence': 3590, 'fort': 1319, 'louis': 1993, 'pondicherry': 2561, 'name': 2247, 'nootropics': 2313, 'stack': 3182, 'balance': 288, 'accept': 23, 'msc': 2221, 'universit': 3532, 'de': 819, 'montral': 2199, 'introduction': 1727, 'gst': 1472, 'meaning': 2094, 'left': 1910, 'retail': 2869, 'product': 2650, 'tax': 3333, 'minority': 2162, 'voilent': 3604, 'poeple': 2546, 'diffrent': 901, 'poltical': 2558, 'beleifs': 337, 'sentence': 3001, 'imprison': 1649, 'savegely': 2952, 'attack': 239, 'trillion': 3466, 'dollar': 950, 'enough': 1092, 'starship': 3191, 'mat': 2075, 'alligator': 105, 'meetic': 2104, 'publicly': 2696, 'quote': 2736, 'avro': 269, 'orc': 2391, 'neil': 2278, 'armstrong': 205, 'telemundo': 3348, 'film': 1260, 'telenovelas': 3349, 'mexico': 2135, 'although': 116, 'headquarters': 1522, 'florida': 1288, 'return': 2872, 'vehicle': 3567, 'psu': 2688, 'join': 1795, 'oil': 2363, 'ongc': 2371, 'select': 2988, 'profile': 2658, 'pay': 2464, 'psus': 2689, 'prefer': 2599, 'undervalued': 3518, 'impact': 1644, 'main': 2026, 'carbohydrate': 496, 'human': 1585, 'diet': 894, 'admit': 54, 'president': 2612, 'congress': 683, 'pass': 2456, 'legislation': 1916, 'daca': 797, 'protect': 2679, 'dreamer': 972, 'eee': 1029, 'branch': 423, 'manipal': 2046, 'pick': 2517, 'coding': 626, 'related': 2817, 'subject': 3244, 'minor': 2161, 'money': 2188, 'launch': 1887, 'consult': 700, 'firm': 1270, 'blanket': 384, 'plug': 2542, 'night': 2301, 'disable': 918, 'source': 3137, 'procurement': 2648, 'folk': 1296, 'crm': 761, 'salesforce': 2940, 'manage': 2035, 'contract': 709, 'almost': 109, 'always': 117, 'ejaculation': 1038, 'erection': 1113, 'normal': 2314, 'srinagar': 3176, 'garhwal': 1384, 'plagiarism': 2529, 'talk': 3323, 'pain': 2429, 'dry': 983, 'fruit': 1363, 'hyderabad': 1599, 'spend': 3157, 'invite': 1740, 'tell': 3351, 'weird': 3655, 'install': 1699, 'usb': 3550, 'performix': 2487, 'sst': 3180, 'fat': 1220, 'burner': 459, 'icy': 1614, 'cold': 632, 'water': 3634, 'hand': 1499, 'gulenist': 1481, 'falsely': 1209, 'crime': 755, 'commit': 651, 'oppress': 2383, 'felt': 1236, 'escape': 1118, 'eternal': 1128, 'torment': 3424, 'germinate': 1408, 'hen': 1538, 'poppy': 2565, 'major': 2031, 'chance': 541, 'artist': 217, 'photo': 2509, 'robot': 2900, 'york': 3742, 'city': 587, 'run': 2922, 'woe': 3698, 'venuas': 3575, 'moon': 2202, 'cry': 770, 'sadness': 2931, 'grow': 1471, 'presidency': 2611, 'scope': 2968, 'communication': 654, 'april': 190, 'barack': 305, 'obama': 2340, 'leverage': 1929, 'borrow': 410, 'viable': 3582, 'option': 2387, 'projector': 2667, 'rupee': 2924, 'scary': 2960, 'gravitational': 1460, 'wave': 3637, 'transmitter': 3453, 'antenna': 164, 'rle': 2895, 'international': 1718, 'chennai': 558, 'development': 879, 'watch': 3633, 'video': 3585, 'knowledge': 1847, 'read': 2772, 'medium': 2102, 'outcome': 2409, 'suppose': 3281, 'guy': 1487, 'collaboration': 634, 'chicken': 563, 'breed': 436, 'produce': 2649, 'extra': 1188, 'yolk': 3741, 'regardless': 2806, 'egg': 1033, 'settle': 3016, 'germany': 1407, 'easy': 1010, 'value': 3560, 'voter': 3611, 'summit': 3266, 'presidential': 2613, 'endorsement': 1078, 'homophobia': 1567, 'group': 1469, 'organic': 2394, 'chemistry': 557, 'diff': 895, 'serotype': 3012, 'biotype': 375, 'bacteria': 284, 'component': 666, 'transition': 3450, 'japanese': 1776, 'culturally': 780, 'diverse': 939, 'neither': 2279, 'destroy': 868, 'admission': 53, 'ipu': 1745, 'llb': 1974, 'divorce': 941, 'narcissistic': 2252, 'ex': 1150, 'sell': 2991, 'explode': 1181, 'redecorate': 2799, 'late': 1882, 'poor': 2562, 'etc': 1127, 'chemical': 556, 'romance': 2906, 'elvis': 1060, 'presley': 2614, 'romantic': 2908, 'possibility': 2580, 'weather': 3643, 'silent': 3058, 'hurricane': 1594, 'factory': 1203, 'reset': 2853, 'macbook': 2017, 'leader': 1895, 'iran': 1747, 'ago': 77, 'fake': 1207, 'toms': 3416, 'torquemada': 3426, 'program': 2662, 'open': 2376, 'software': 3112, 'laser': 1879, 'blavk': 385, 'around': 208, 'spicy': 3158, 'italian': 1764, 'recipe': 2787, 'productivity': 2653, 'income': 1656, 'closed': 610, 'jerk': 1783, 'online': 2372, 'background': 282, 'check': 555, 'prompt': 2670, 'billing': 364, 'rattlesnake': 2766, 'deserve': 864, 'happiness': 1504, 'control': 714, 'due': 985, 'unlocked': 3534, 'door': 959, 'among': 132, 'strenghts': 3228, 'preschool': 2608, 'possess': 2579, 'society': 3110, 'react': 2771, 'nda': 2268, 'intelligent': 1713, 'sad': 2930, 'age': 72, 'biological': 371, 'researcher': 2849, 'count': 735, 'dooku': 958, 'sith': 3079, 'lord': 1986, 'success': 3252, 'effort': 1032, 'territory': 3365, 'aboriginal': 7, 'bodhi': 401, 'animal': 150, 'legally': 1914, 'link': 1958, 'anymore': 168, 'input': 1691, 'subsidy': 3249, 'exciting': 1161, 'essay': 1124, 'pakistan': 2431, 'pas': 2453, 'sikh': 3056, 'marriage': 2066, 'another': 160, 'hello': 1533, 'living': 1972, 'ghetto': 1411, 'christian': 578, 'devotional': 883, 'working': 3710, 'septic': 3007, 'tank': 3326, 'overflow': 2414, 'survivor': 3292, 'family': 1211, 'victim': 3584, 'esp': 1122, 'fire': 1268, 'middle': 2142, 'easterner': 1009, 'nomad': 2309, 'mongol': 2191, 'eat': 1011, 'meal': 2092, 'psychology': 2692, 'listen': 1964, 'kpop': 1855, 'music': 2236, 'nationalism': 2258, 'tinting': 3405, 'greenville': 1464, 'sc': 2954, 'hr': 1582, 'shoulder': 3041, 'corporate': 724, 'bond': 404, 'tip': 3406, 'raymond': 2768, 'james': 1774, 'last': 1881, 'layer': 1890, 'stubborn': 3235, 'apply': 181, 'junior': 1806, 'isro': 1761, 'creative': 750, 'train': 3441, 'raccoon': 2737, 'forgive': 1316, 'catch': 513, 'favorite': 1223, 'celibrity': 522, 'lifetime': 1944, 'fantasy': 1215, 'pirate': 2524, 'content': 706, 'violation': 3589, 'precept': 2598, 'buddhism': 451, 'arrange': 209, 'previous': 2622, 'generation': 1395, 'entire': 1096, 'duration': 989, 'occam': 2350, 'razor': 2769, 'tackle': 3318, 'obsession': 2348, 'advantage': 60, 'disadvantage': 919, 'automatic': 261, 'headlamp': 1521, 'aho': 80, 'especially': 1123, 'wheeler': 3669, 'daily': 802, 'ecomonic': 1015, 'condition': 678, 'personality': 2495, 'manga': 2042, 'draw': 970, 'manual': 2050, 'script': 2972, 'detail': 870, 'important': 1647, 'battle': 317, 'kyber': 1860, 'token': 3412, 'oct': 2353, 'taskbar': 3331, 'respond': 2861, 'answer': 161, 'image': 1636, 'blog': 392, 'credit': 752, 'author': 259, 'republicans': 2844, 'government': 1443, 'fit': 1273, 'parliament': 2445, 'abolish': 6, 'topik': 3422, 'exam': 1153, 'steak': 3202, 'dis': 917, 'mongodb': 2189, 'server': 3013, 'mongodump': 2190, 'mongorestore': 2192, 'hesitate': 1542, 'humiliate': 1588, 'hindi': 1550, 'ese': 1120, 'civil': 589, 'mark': 2061, 'ingredio': 1686, 'milk': 2149, 'shake': 3026, 'transient': 3448, 'voltage': 3606, 'bass': 313, 'poem': 2545, 'ramayana': 2752, 'ancient': 143, 'epic': 1104, 'literature': 1967, 'muslim': 2238, 'happy': 1505, 'jihad': 1788, 'suffer': 3257, 'rule': 2921, 'investigation': 1736, 'tool': 3418, 'police': 2551, 'famous': 1212, 'polygamist': 2559, 'indonesia': 1669, 'trusted': 3477, 'site': 3078, 'scholarship': 2962, 'score': 2969, 'history': 1556, 'graduation': 1449, 'lecture': 1907, 'neet': 2274, 'pg': 2498, 'mbbs': 2089, 'bachelor': 279, 'queensland': 2724, 'rise': 2891, 'sectional': 2982, 'percentile': 2483, 'lrdi': 2000, 'di': 885, 'english': 1088, 'scientific': 2966, 'research': 2848, 'publish': 2697, 'amount': 133, 'alternative': 115, 'funding': 1372, 'quality': 2718, 'bushfires': 462, 'clean': 597, 'remington': 2830, 'woodmaster': 3703, 'officer': 2359, 'administrative': 51, 'joe': 1793, 'negotiate': 2275, 'inequality': 1674, 'revit': 2876, 'primary': 2626, 'stress': 3230, 'disorder': 931, 'soy': 3143, 'latte': 1885, 'healthy': 1524, 'drink': 975, 'deployed': 856, 'army': 206, 'ranger': 2756, 'steam': 3205, 'gift': 1416, 'clutch': 617, 'activa': 38, 'compliance': 665, 'exceptionally': 1159, 'profound': 2661, 'dominant': 953, 'verbal': 3576, 'weight': 3653, 'laptop': 1876, 'attract': 244, 'confirmation': 681, 'hour': 1577, 'lawyer': 1889, 'samsung': 2942, 'galaxy': 1378, 'edge': 1022, 'pc': 2468, 'flash': 1280, 'drive': 976, 'fix': 1275, 'stalin': 3184, 'thought': 3386, 'era': 1111, 'soviet': 3140, 'union': 3526, 'spartan': 3146, 'roman': 2905, 'reply': 2839, 'little': 1969, 'jocularly': 1792, 'analyst': 139, 'cricket': 754, 'deoxyribose': 854, 'ribose': 2883, 'sugar': 3259, 'mom': 2186, 'son': 3129, 'dear': 823, 'zindagi': 3748, 'oprah': 2384, 'pope': 2564, 'curse': 788, 'mba': 2088, 'suitable': 3263, 'doctor': 946, 'private': 2636, 'conquer': 686, 'ireland': 1748, 'fail': 1204, 'scotland': 2970, 'gas': 1385, 'station': 3196, 'ladder': 1864, 'operator': 2379, 'method': 2133, 'determine': 873, 'eigenvalue': 1035, 'quantum': 2721, 'harmonic': 1509, 'oscillator': 2403, 'xrp': 3730, 'gain': 1377, 'mass': 2071, 'adoption': 57, 'likely': 1949, 'native': 2262, 'spain': 3145, 'coffee': 627, 'productive': 2652, 'advanced': 59, 'currently': 787, 'extinct': 1187, 'lapse': 1875, 'plane': 2531, 'heathrow': 1530, 'airport': 89, 'royal': 2918, 'guard': 1474, 'exclude': 1162, 'uber': 3500, 'airbnb': 85, 'referral': 2804, 'hear': 1525, 'conflict': 682, 'suhrawardy': 3260, 'bhashani': 354, 'airticket': 90, 'amadeus': 119, 'ca': 466, 'businessman': 464, 'weed': 3650, 'antidepressant': 166, 'instagram': 1698, 'past': 2458, 'must': 2239, 'textbook': 3371, 'philosophical': 2506, 'logic': 1981, 'absolute': 13, 'beginner': 332, 'sri': 3175, 'lankan': 1874, 'understand': 3517, 'ltte': 2003, 'benefit': 341, 'lanka': 1873, 'ill': 1632, 'intention': 1714, 'consume': 702, 'educational': 1026, 'material': 2077, 'follower': 1299, 'anonymous': 159, 'anonymity': 158, 'lady': 1865, 'macbeth': 2016, 'plan': 2530, 'duncan': 987, 'shakespeare': 3027, 'gulf': 1482, 'post': 2583, 'democratic': 849, 'personally': 2496, 'superstition': 3276, 'blindly': 389, 'believe': 339, 'educate': 1024, 'convince': 719, 'develop': 876, 'instead': 1703, 'swift': 3303, 'mindset': 2154, 'motif': 2210, 'westerner': 3661, 'isi': 1755, 'delivery': 846, 'partner': 2451, 'lsi': 2001, 'corporation': 725, 'constantly': 697, 'uneasy': 3520, 'split': 3164, 'squat': 3174, 'lunge': 2010, 'entrepreneurship': 1099, 'art': 212, 'bamford': 292, 'imucet': 1653, 'seem': 2985, 'empowerment': 1073, 'auditor': 252, 'dialect': 887, 'unstressed': 3537, 'precede': 2597, 'blender': 387, 'nasalized': 2255, 'tap': 3327, 'n': 2338, 'n': 2339, 'dropping': 981, 'merger': 2122, 'meet': 2103, 'heaven': 1531, 'john': 1794, 'diggle': 902, 'arrow': 211, 'crisis': 757, 'conclusively': 676, 'show': 3043, 'mantle': 2049, 'william': 3682, 'necessary': 2272, 'disclose': 924, 'salary': 2937, 'employer': 1071, 'optionals': 2388, 'pcs': 2469, 'relational': 2819, 'algebra': 97, 'basis': 311, 'database': 812, 'structural': 3232, 'shift': 3031, 'discussion': 926, 'deviantart': 880, 'fetish': 1241, 'prevalent': 2620, 'moderate': 2178, 'tyrannical': 3497, 'mail': 2025, 'july': 1803, 'kind': 1833, 'therapy': 3380, 'forget': 1315, 'memory': 2114, 'hypnosis': 1602, 'perfecty': 2484, 'hit': 1557, 'single': 3074, 'easily': 1006, 'stuter': 3240, 'breathe': 435, 'superhero': 3273, 'beat': 324, 'superman': 3275, 'strong': 3231, 'maverick': 2083, 'indecisive': 1659, 'person': 2493, 'trade': 3436, 'copanies': 721, 'demographic': 850, 'customer': 791, 'magic': 2022, 'lucas': 2004, 'sequence': 3008, 'fibonacci': 1247, 'hunch': 1591, 'turn': 3488, 'smart': 3099, 'crack': 746, 'jee': 1782, 'advance': 58, 'air': 84, 'study': 3238, 'political': 2555, 'fumbling': 1367, 'recognizable': 2789, 'short': 3037, 'story': 3221, 'shave': 3029, 'hair': 1493, 'leg': 1912, 'real': 2776, 'wordpress': 3706, 'follow': 1298, 'loan': 1976, 'director': 914, 'nri': 2326, 'sox': 3142, 'series': 3010, 'netherlands': 2282, 'call': 476, 'dutch': 990, 'asian': 221, 'mask': 2070, 'chinese': 570, 'fortune': 1322, 'stick': 3211, 'carrier': 505, 'uk': 3504, 'angry': 148, 'brain': 420, 'electrostatic': 1050, 'revolve': 2879, 'electron': 1047, 'centripetal': 528, 'bikini': 362, 'clock': 608, 'morning': 2204, 'dimension': 907, 'table': 3315, 'mandrill': 2041, 'layperson': 1891, 'profit': 2659, 'currency': 785, 'failing': 1205, 'certain': 530, 'die': 892, 'abortion': 8, 'save': 2951, 'analyze': 140, 'national': 2257, 'economist': 1019, 'bansal': 303, 'sheet': 3030, 'religious': 2825, 'afraid': 69, 'decease': 830, 'bathroom': 314, 'masturbate': 2074, 'toy': 3434, 'wooden': 3702, 'boat': 399, 'kilogram': 1831, 'chevrolet': 561, 'caprice': 492, 'ppv': 2594, 'primarily': 2625, 'compete': 659, 'franchise': 1335, 'surat': 3282, 'gujarat': 1479, 'economic': 1016, 'icse': 1613, 'examinaton': 1155, 'radar': 2742, 'guidance': 1477, 'gun': 1483, 'nudity': 2331, 'profanity': 2654, 'delete': 843, 'restaurant': 2865, 'nice': 2297, 'insurance': 1709, 'damage': 805, 'grab': 1446, 'seat': 2978, 'quota': 2735, 'west': 3659, 'bengal': 342, 'abroad': 10, 'somewhere': 3128, 'sister': 3076, 'min': 2152, 'ride': 2888, 'im': 1635, 'curvature': 789, 'humongous': 1589, 'net': 2281, 'curve': 790, 'face': 1196, 'mild': 2145, 'colleague': 637, 'skip': 3088, 'meeting': 2105, 'electromagnetic': 1046, 'interference': 1716, 'distinguish': 936, 'relative': 2821, 'scale': 2956, 'breath': 434, 'drug': 982, 'trafficking': 3440, 'fetal': 1240, 'rate': 2762, 'pregnancy': 2600, 'pad': 2423, 'together': 3411, 'similarity': 3062, 'domain': 951, 'cognizant': 629, 'monster': 2195, 'alphabet': 112, 'dictionary': 891, 'invent': 1732, 'portfolio': 2574, 'heat': 1529, 'directly': 913, 'elecric': 1040, 'body': 402, 'finix': 1267, 'coin': 631, 'ico': 1612, 'legit': 1917, 'scam': 2957, 'phd': 2501, 'mit': 2172, 'caltech': 477, 'berkeley': 343, 'comment': 649, 'rounding': 2916, 'weevil': 3652, 'infestation': 1678, 'treatment': 3458, 'matrix': 2081, 'mistake': 2170, 'chess': 560, 'writer': 3722, 'dilute': 906, 'urine': 3547, 'addisons': 48, 'disease': 927, 'supercharge': 3272, 'ic': 1610, 'stiffness': 3212, 'attracts': 246, 'load': 1975, 'beam': 321, 'somen': 3124, 'design': 865, 'experiment': 1177, 'reincarnation': 2812, 'remember': 2829, 'respectful': 2860, 'successful': 3253, 'entrepreneur': 1098, 'millionaire': 2151, 'billionaire': 366, 'politics': 2557, 'fluent': 1291, 'ghanaian': 1410, 'nigerian': 2300, 'objectively': 2345, 'powerful': 2593, 'universe': 3530, 'popular': 2566, 'nyt': 2337, 'memo': 2112, 'whereas': 3671, 'wsj': 3725, 'bias': 356, 'mantis': 2048, 'shrimp': 3045, 'consist': 693, 'linguistic': 1956, 'differential': 898, 'actual': 43, 'graph': 1457, 'scalability': 2955, 'expert': 1178, 'mostly': 2208, 'unconnected': 3511, 'waffle': 3615, 'teddy': 3344, 'bear': 322, 'hamster': 1498, 'imagine': 1637, 'fiction': 1248, 'sound': 3136, 'annual': 157, 'engineer': 1085, 'tooth': 3419, 'forming': 1318, 'already': 113, 'helpful': 1535, 'drop': 978, 'result': 2867, 'approve': 186, 'accurate': 30, 'description': 862, 'mucus': 2226, 'early': 999, 'roosevelt': 2912, 'befriend': 330, 'physical': 2513, 'strength': 3229, 'ready': 2775, 'overpower': 2416, 'tie': 3398, 'gag': 1376, 'safety': 2934, 'recomend': 2791, 'dish': 929, 'tasty': 3332, 'employment': 1072, 'yacht': 3733, 'represent': 2842, 'employ': 1069, 'vessel': 3580, 'wbjee': 3640, 'california': 475, 'practical': 2595, 'learning': 1901, 'ecology': 1014, 'conservation': 688, 'biology': 372, 'environmental': 1102, 'powder': 2590, 'rifle': 2889, 'specific': 3152, 'introduce': 1726, 'opportunity': 2381, 'transaction': 3444, 'fiduciary': 1250, 'advisor': 64, 'steal': 3203, 'prove': 2683, 'govt': 1445, 'medical': 2099, 'colege': 633, 'ramk': 2753, 'reading': 2774, 'wire': 3689, 'ground': 1468, 'bar': 304, 'close': 609, 'guess': 1476, 'prize': 2637, 'purches': 2706, 'dmt': 942, 'orange': 2389, 'boiled': 403, 'noodle': 2312, 'paddy': 2424, 'herb': 1540, 'care': 500, 'sensitivity': 3000, 'sometimes': 3127, 'half': 1494, 'cse': 774, 'vit': 3596, 'rank': 2757, 'legal': 1913, 'debtor': 829, 'quit': 2730, 'creditor': 753, 'collection': 638, 'unemployment': 3521, 'suddenly': 3256, 'disappear': 920, 'networking': 2283, 'mining': 2159, 'dream': 971, 'jinping': 1790, 'serial': 3009, 'religion': 2824, 'murderer': 2234, 'rapist': 2759, 'mao': 2053, 'ammonium': 131, 'bicarbonate': 357, 'production': 2651, 'bread': 426, 'jat': 1777, 'gujjar': 1480, 'beautiful': 325, 'box': 415, 'ammo': 130, 'bullet': 455, 'firework': 1269, 'impression': 1648, 'compound': 667, 'sci': 2964, 'graduate': 1448, 'marine': 2060, 'gme': 1428, 'mumbai': 2232, 'wild': 3681, 'ilustrator': 1634, 'require': 2846, 'tinder': 3404, 'nothing': 2319, 'succeed': 3251, 'effect': 1030, 'polythene': 2560, 'bureau': 456, 'investigate': 1735, 'homicide': 1566, 'fbi': 1225, 'tunisian': 3485, 'welfare': 3657, 'charity': 551, 'epecially': 1103, 'limit': 1951, 'contribute': 711, 'philadelphia': 2503, 'baltimore': 291, 'howie': 1581, 'seago': 2975, 'accomplishment': 27, 'actor': 41, 'bleeding': 386, 'clot': 611, 'sleep': 3092, 'graveyard': 1459, 'trouble': 3471, 'awake': 270, 'babyface': 278, 'wwe': 3726, 'topic': 3421, 'management': 2036, 'challenge': 539, 'lori': 1987, 'anne': 155, 'allison': 106, 'makeup': 2033, 'remote': 2831, 'aadhar': 1, 'bandhup': 296, 'lb': 1893, 'marg': 2058, 'objective': 2344, 'criterion': 758, 'evaluate': 1133, 'cell': 523, 'range': 2755, 'less': 1923, 'attendance': 241, 'bush': 461, 'correct': 727, 'centre': 527, 'correction': 728, 'fee': 1233, 'cutoff': 793, 'delhi': 844, 'ray': 2767, 'converge': 715, 'earth': 1003, 'atmosphere': 235, 'captain': 493, 'phasma': 2500, 'somehow': 3123, 'trick': 3464, 'gang': 1382, 'ba': 275, 'suicide': 3261, 'racism': 2740, 'protest': 2680, 'padmaavat': 2425, 'padmavati': 2426, 'rotate': 2913, 'east': 1007, 'footballer': 1306, 'lte': 2002, 'volta': 3605, 'facility': 1199, 'forwarding': 1323, 'whatsapp': 3666, 'cocktail': 624, 'wedding': 3649, 'common': 653, 'injury': 1690, 'friendly': 1353, 'operation': 2378, 'carpet': 504, 'installation': 1700, 'invoice': 1741, 'template': 3355, 'debate': 825, 'mess': 2128, 'kosovo': 1853, 'albanian': 94, 'born': 409, 'alive': 102, 'worker': 3708, 'handle': 1500, 'secure': 2983, 'cash': 508, 'earnings': 1001, 'payment': 2466, 'aa': 0, 'recruitment': 2797, 'complete': 663, 'deduct': 837, 'mu': 2224, 'oet': 2356, 'usc': 3551, 'teenager': 3346, 'holder': 1560, 'fan': 1213, 'itunes': 1770, 'robin': 2899, 'gibb': 1414, 'singer': 3072, 'amendment': 126, 'worry': 3714, 'budget': 452, 'camping': 482, 'jaisalmer': 1773, 'humour': 1590, 'joke': 1796, 'leigh': 1918, 'francis': 1337, 'fictional': 1249, 'keith': 1817, 'lemon': 1919, 'telugu': 3352, 'blood': 393, 'cough': 731, 'mack': 2020, 'whatis': 3664, 'stag': 3183, 'buck': 450, 'cultural': 779, 'taboo': 3317, 'russia': 2926, 'articleship': 215, 'available': 265, 'anti': 165, 'semite': 2994, 'burke': 457, 'deaf': 821, 'professionals': 2656, 'depression': 859, 'disassemble': 921, 'revolver': 2880, 'nintendo': 2305, 'switch': 3305, 'store': 3220, 'ticket': 3397, 'london': 1983, 'quickly': 2728, 'breakdance': 429, 'stereotype': 3208, 'attach': 238, 'sydney': 3306, 'northern': 2316, 'beach': 320, 'inflation': 1680, 'electrician': 1044, 'summary': 3264, 'streetcar': 3227, 'broker': 443, 'estate': 1126, 'agent': 74, 'whats': 3665, 'cleanshot': 598, 'express': 1185, 'feeling': 1235, 'irrespective': 1752, 'barkha': 306, 'dutt': 991, 'newsx': 2292, 'twitter': 3493, 'hire': 1553, 'swagatham': 3297, 'csa': 773, 'iisc': 1629, 'gate': 1386, 'topper': 3423, 'others': 2405, 'also': 114, 'otherwise': 2406, 'three': 3389, 'hashtags': 1515, 'nearly': 2270, 'however': 1580, 'traffic': 3439, 'wrong': 3723, 'apparel': 175, 'industry': 1673, 'consultant': 701, 'qualification': 2717, 'favourite': 1224, 'listed': 1963, 'unlisted': 3533, 'truth': 3478, 'matter': 2082, 'analog': 137, 'nazi': 2267, 'throw': 3394, 'ice': 1611, 'cube': 777, 'ocean': 2352, 'molecule': 2185, 'acer': 32, 'aspire': 226, 'detect': 871, 'forcibly': 1308, 'sunni': 3270, 'wahabbi': 3617, 'islam': 1756, 'princeton': 2631, 'urban': 3545, 'local': 1977, 'constitute': 698, 'yin': 3740, 'yang': 3734, 'originate': 2400, 'consideration': 691, 'hank': 1502, 'hill': 1548, 'costume': 730, 'iron': 1750, 'humans': 1587, 'solidify': 3117, 'maintain': 2029, 'search': 2976, 'graf': 1450, 'death': 824, 'threat': 3387, 'elevator': 1052, 'end': 1077, 'neutrality': 2286, 'traditional': 3438, 'rebound': 2784, 'mine': 2155, 'version': 3579, 'wrestler': 3718, 'agency': 73, 'arrest': 210, 'sit': 3077, 'jute': 1809, 'exporter': 1184, 'bangladesh': 298, 'europe': 1130, 'tum': 3484, 'master': 2073, 'recommender': 2794, 'temperature': 3354, 'slightly': 3094, 'feverish': 1244, 'concern': 673, 'summer': 3265, 'internship': 1720, 'aspirant': 225, 'melancholia': 2108, 'childhood': 566, 'adversity': 61, 'prime': 2628, 'motivator': 2214, 'genetic': 1396, 'tolerance': 3414, 'childbirth': 565, 'menstrual': 2116, 'breastfeeding': 433, 'historical': 1555, 'significance': 3054, 'mesopotamia': 2127, 'ironic': 1751, 'salem': 2939, 'hang': 1501, 'crucible': 766, 'sight': 3051, 'akshay': 91, 'thakre': 3374, 'everyone': 1142, 'hat': 1516, 'staring': 3190, 'key': 1822, 'mock': 2175, 'aiims': 82, 'distribute': 937, 'tomorrow': 3415, 'lg': 1933, 'tempature': 3353, 'smack': 3097, 'aerogel': 65, 'expensive': 1175, 'walk': 3621, 'rain': 2749, 'plural': 2543, 'mathematics': 2080, 'amazing': 123, 'everybody': 1140, 'else': 1059, 'asexuality': 219, 'either': 1036, 'childish': 567, 'paris': 2443, 'tibetan': 3396, 'wording': 3705, 'groupon': 1470, 'submit': 3247, 'jorge': 1798, 'luis': 2006, 'borges': 408, 'sure': 3284, 'implement': 1646, 'intersection': 1721, 'fraud': 1339, 'hospital': 1573, 'disrespect': 934, 'exhaust': 1166, 'audi': 248, 'shower': 3044, 'breakfast': 430, 'constant': 696, 'volume': 3607, 'pressure': 2615, 'absorb': 15, 'bird': 378, 'gir': 1417, 'forest': 1313, 'freeze': 1345, 'threaten': 3388, 'knowingly': 1846, 'heartbeat': 1528, 'inject': 1688, 'anesthetic': 145, 'surgery': 3288, 'rush': 2925, 'absolutely': 14, 'numbing': 2334, 'whatsoever': 3667, 'horrible': 1572, 'bloodstream': 394, 'cryptorchidism': 771, 'okay': 2365, 'respect': 2859, 'colonial': 641, 'empires': 1068, 'swap': 3299, 'identity': 1621, 'debt': 828, 'forever': 1314, 'graphic': 1458, 'ordinary': 2393, 'orthodox': 2401, 'argument': 198, 'filioque': 1257, 'bipolar': 376, 'economically': 1017, 'wage': 3616, 'enter': 1093, 'workforce': 3709, 'waterproof': 3635, 'resent': 2850, 'address': 49, 'genre': 1400, 'goony': 1437, 'stand': 3187, 'fable': 1195, 'folktale': 1297, 'snapchat': 3105, 'popularity': 2567, 'decline': 835, 'chairman': 538, 'regional': 2808, 'federal': 1232, 'reserve': 2852, 'canada': 483, 'pursue': 2710, 'banking': 301, 'finance': 1263, 'colour': 643, 'methyl': 2134, 'limewater': 1950, 'itchiness': 1767, 'breast': 432, 'comrade': 670, 'ia': 1606, 'ip': 1743, 'ifs': 1623, 'ies': 1622, 'mentally': 2118, 'retard': 2870, 'autonomous': 264, 'clinic': 604, 'amaze': 122, 'activist': 40, 'extremely': 1191, 'relate': 2816, 'command': 648, 'running': 2923, 'shoe': 3033, 'flat': 1281, 'foot': 1304, 'cubic': 778, 'liter': 1966, 'us': 3548, 'certificate': 531, 'level': 1928, 'martial': 2069, 'record': 2795, 'electrical': 1043, 'intrested': 1725, 'equipment': 1110, 'administrator': 52, 'gopal': 1439, 'krishna': 1856, 'gokhale': 1433, 'mentor': 2119, 'gandhi': 1381, 'quirky': 2729, 'throne': 3392, 'arya': 218, 'littlefinger': 1970, 'undergraduate': 3512, 'integrated': 1711, 'paper': 2437, 'degree': 842, 'deter': 872, 'better': 348, 'moment': 2187, 'walmartlabs': 3624, 'grant': 1454, 'rsu': 2919, 'vest': 3581, 'syria': 3313, 'hispanic': 1554, 'proud': 2682, 'prospect': 2678, 'automation': 263, 'audio': 250, 'device': 881, 'specially': 3151, 'speed': 3155, 'interstate': 1722, 'highway': 1546, 'road': 2897, 'waste': 3632, 'limited': 1952, 'eso': 1121, 'collar': 636, 'hypothesis': 1604, 'cancer': 487, 'calcium': 470, 'channel': 545, 'blocker': 391, 'cope': 722, 'jealous': 1780, 'governmental': 1444, 'organisation': 2395, 'hide': 1544, 'reward': 2881, 'virtual': 3592, 'assistant': 230, 'stanford': 3189, 'criticise': 760, 'indie': 1667, 'upsc': 3544, 'sanction': 2944, 'faith': 1206, 'season': 2977, 'indicate': 1666, 'authoritarian': 260, 'harsh': 1511, 'husky': 1597, 'sustain': 3295, 'tropical': 3470, 'environment': 1101, 'prerequisite': 2607, 'professor': 2657, 'mtech': 2223, 'aggregate': 75, 'christianity': 579, 'augustus': 253, 'synapsis': 3311, 'besides': 344, 'brit': 440, 'queen': 2723, 'elizabeth': 1057, 'king': 1834, 'henry': 1539, 'viii': 3587, 'drain': 968, 'fly': 1292, 'sewage': 3021, 'cow': 744, 'ungrateful': 3523, 'america': 127, 'speaking': 3148, 'german': 1406, 'cover': 743, 'clown': 615, 'harvard': 1512, 'ecosystem': 1021, 'prototype': 2681, 'inventor': 1733, 'tier': 3399, 'tapmi': 3328, 'bim': 367, 'kj': 1838, 'somaiya': 3121, 'lease': 1902, 'agreement': 78, 'tc': 3335, 'wipro': 3688, 'infosys': 1684, 'training': 3442, 'supplement': 3277, 'boob': 405, 'concerned': 674, 'carter': 506, 'russian': 2927, 'spy': 3169, 'sense': 2998, 'immigrate': 1640, 'britain': 441, 'fl': 1277, 'id': 1615, 'issuance': 1762, 'citation': 585, 'infraction': 1685, 'electric': 1042, 'gear': 1389, 'impersonal': 1645, 'wet': 3662, 'deal': 822, 'withdrawal': 3693, 'wechat': 3648, 'symbol': 3309, 'tuition': 3482, 'siliceous': 3059, 'ooze': 2375, 'wan': 3626, 'na': 2246, 'flipkart': 1286, 'fixed': 1276, 'reference': 2803, 'frame': 1332, 'dilation': 905, 'thin': 3381, 'plat': 2534, 'armour': 204, 'folded': 1295, 'leather': 1905, 'underneath': 3515, 'knight': 1843, 'armor': 203, 'bandeau': 295, 'outfit': 2410, 'simlarity': 3063, 'arichtecture': 199, 'roller': 2904, 'coaster': 623, 'civic': 588, 'except': 1158, 'eventuality': 1137, 'prepared': 2606, 'collapse': 635, 'gender': 1390, 'physically': 2514, 'gmail': 1427, 'mac': 2015, 'sidebar': 3050, 'along': 111, 'often': 2361, 'connection': 685, 'cardiac': 498, 'filling': 1259, 'cctv': 519, 'surveillance': 3290, 'despite': 867, 'abuse': 18, 'notify': 2321, 'tweeter': 3490, 'hack': 1490, 'pornographic': 2571, 'message': 2129, 'mcu': 2091, 'villain': 3588, 'cant': 489, 'developed': 877, 'armfeldt': 202, 'lewenhaupt': 1932, 'rehnskild': 2811, 'swedish': 3301, 'general': 1392, 'psychopath': 2693, 'acceptance': 24, 'caring': 503, 'cheat': 554, 'sql': 3171, 'fun': 1368, 'western': 3660, 'gaming': 1380, 'significant': 3055, 'logarithm': 1980, 'processing': 2645, 'banglore': 299, 'safest': 2933, 'nudge': 2330, 'hike': 1547, 'funny': 1374, 'rotation': 2914, 'polarity': 2550, 'active': 39, 'coast': 622, 'dynamic': 994, 'idc': 1616, 'lazyness': 1892, 'away': 272, 'posion': 2575, 'mintues': 2164, 'prison': 2635, 'dad': 799, 'unnecessarily': 3535, 'sibling': 3047, 'thaads': 3372, 'hybrid': 1598, 'wheel': 3668, 'married': 2067, 'donald': 955, 'news': 2291, 'host': 1574, 'improvement': 1652, 'population': 2568, 'nra': 2325, 'evil': 1147, 'skinny': 3087, 'jean': 1781, 'hammer': 1497, 'dagenhart': 801, 'partially': 2447, 'homeowner': 1564, 'begin': 331, 'put': 2712, 'panel': 2435, 'roof': 2910, 'en': 1075, 'masse': 2072, 'clip': 606, 'tv': 3489, 'upload': 3542, 'watery': 3636, 'discharge': 923, 'pregnant': 2601, 'mum': 2231, 'apparently': 177, 'twice': 3491, 'bankruptcy': 302, 'thunderstike': 3395, 'reveal': 2873, 'throughout': 3393, 'genome': 1399, 'platypus': 2536, 'renewable': 2835, 'feasibility': 1230, 'evaluation': 1134, 'lut': 2011, 'ewg': 1148, 'flaw': 1283, 'marked': 2062, 'rat': 2761, 'penetrate': 2477, 'venomous': 3573, 'snake': 3104, 'bite': 380, 'sick': 3048, 'venom': 3572, 'cure': 784, 'harm': 1507, 'proceed': 2643, 'amplify': 135, 'signal': 3053, 'recipient': 2788, 'lifeguard': 1941, 'aquatic': 192, 'diameter': 888, 'bob': 400, 'pendulum': 2476, 'multiplication': 2230, 'quantitative': 2720, 'percentage': 2482, 'intuitive': 1730, 'route': 2917, 'houston': 1579, 'san': 2943, 'francisco': 1338, 'structure': 3233, 'conversion': 717, 'bba': 318, 'bbm': 319, 'comedk': 647, 'motivation': 2213, 'receive': 2785, 'lotion': 1991, 'alone': 110, 'hypothetically': 1605, 'fill': 1258, 'grenade': 1465, 'enemy': 1080, 'combatant': 645, 'syllabic': 3308, 'consonant': 695, 'sanskrit': 2945, 'varnamala': 3564, 'vowel': 3612, 'clothes': 612, 'article': 214, 'journal': 1799, 'tow': 3431, 'total': 3428, 'obedience': 2342, 'creature': 751, 'dental': 851, 'marketing': 2065, 'dentist': 852, 'cambridge': 478, 'pune': 2699, 'chapter': 546, 'assignment': 229, 'revoke': 2877, 'pound': 2589, 'yes': 3737, 'apple': 179, 'radio': 2743, 'surge': 3286, 'member': 2111, 'part': 2446, 'incorporate': 1657, 'ike': 1631, 'ibeabuchi': 1609, 'somebody': 3122, 'guide': 1478, 'purchase': 2705, 'exercise': 1165, 'pleasure': 2541, 'enema': 1079, 'walter': 3625, 'bedell': 327, 'beetle': 329, 'kenya': 1820, 'foe': 1294, 'resident': 2854, 'suspension': 3294, 'profitable': 2660, 'leasing': 1903, 'plant': 2533, 'indoor': 1671, 'maintanable': 2030, 'newly': 2290, 'retire': 2871, 'midnight': 2143, 'kota': 1854, 'swing': 3304, 'mood': 2201, 'kennedy': 1819, 'beijing': 336, 'cone': 680, 'next': 2293, 'park': 2444, 'container': 705, 'render': 2834, 'presentation': 2610, 'ronaldinho': 2909, 'casual': 511, 'present': 2609, 'minister': 2160, 'karnataka': 1814, 'korean': 1852, 'parade': 2439, 'march': 2056, 'exaggerated': 1152, 'goose': 1438, 'unsuccessful': 3538, 'prey': 2623, 'soon': 3131, 'bos': 411, 'porn': 2570, 'imortant': 1643, 'tall': 3324, 'sportsman': 3167, 'strategy': 3224, 'startup': 3193, 'reach': 2770, 'target': 3329, 'audience': 249, 'ad': 45, 'devil': 882, 'grandmother': 1453, 'wrestling': 3719, 'wrastling': 3717, 'sudden': 3255, 'intrusive': 1729, 'crochet': 762, 'scarf': 2959, 'pattern': 2460, 'brian': 438, 'griffin': 1466, 'frequently': 1350, 'itchy': 1768, 'apparent': 176, 'usually': 3557, 'isolated': 1758, 'gene': 1391, 'allele': 103, 'con': 671, 'surface': 3285, 'accord': 28, 'pet': 2497, 'belief': 338, 'elite': 1056, 'paycheck': 2465, 'plus': 2544, 'debit': 827, 'mp': 2220, 'sasuke': 2948, 'naruto': 2254, 'indra': 1672, 'ashura': 220, 'brother': 445, 'phrase': 2511, 'economics': 1018, 'player': 2538, 'bjp': 381, 'punjab': 2702, 'shouldnt': 3042, 'executive': 1163, 'contribution': 712, 'abandoned': 2, 'campania': 480, 'italy': 1765, 'lyft': 2013, 'reinstall': 2814, 'loved': 1998, 'naval': 2265, 'agni': 76, 'missile': 2168, 'mughals': 2227, 'descendant': 861, 'genghis': 1398, 'khan': 1824, 'lifehacks': 1942, 'kick': 1826, 'function': 1369, 'amylose': 136, 'basketball': 312, 'france': 1334, 'cme': 619, 'motorcycle': 2215, 'toronto': 3425, 'exempt': 1164, 'motion': 2211, 'whiteboard': 3677, 'lunch': 2008, 'cramp': 747, 'um': 3505, 'uncomfortable': 3509, 'response': 2862, 'nucleus': 2329, 'insist': 1696, 'kubernetes': 1857, 'backend': 281, 'docker': 945, 'cto': 776, 'dating': 815, 'bore': 407, 'diffferently': 899, 'stream': 3225, 'pixelated': 2526, 'choppy': 576, 'subcontinent': 3243, 'girlfriend': 1419, 'sufficient': 3258, 'workplace': 3712, 'ham': 1496, 'licencing': 1936, 'asoc': 224, 'examination': 1154, 'welcome': 3656, 'cloud': 614, 'solid': 3116, 'frieza': 1356, 'adam': 46, 'angelo': 146, 'kim': 1832, 'kardasian': 1813, 'novel': 2324, 'recommend': 2792, 'actress': 42, 'harvey': 1513, 'weinstein': 3654, 'queer': 2725, 'separation': 3005, 'nuremberg': 2335, 'earphone': 1002, 'mobile': 2174, 'partition': 2450, 'attitudes': 242, 'catchweight': 514, 'match': 2076, 'overlay': 2415, 'levi': 1930, 'forecast': 1309, 'commodity': 652, 'iq': 1746, 'leroy': 1922, 'robert': 2898, 'satchel': 2949, 'paige': 2428, 'mar': 2055, 'perfume': 2488, 'underground': 3513, 'pimple': 2521, 'hurt': 1595, 'pop': 2563, 'chad': 536, 'ancestor': 141, 'wolf': 3699, 'wolverine': 3700, 'virgin': 3591, 'blow': 396, 'koran': 1850, 'translation': 3452, 'raisin': 2750, 'rare': 2760, 'delicacy': 845, 'sap': 2946, 'ewm': 1149, 'foundation': 1327, 'ritzman': 2893, 'cdn': 520, 'positively': 2577, 'globalization': 1425, 'eyeliner': 1194, 'lashline': 1880, 'diesel': 893, 'locomotive': 1979, 'railway': 2748, 'double': 961, 'circulation': 584, 'trend': 3461, 'careamics': 501, 'display': 932, 'amateur': 121, 'reader': 2773, 'swear': 3300, 'emotion': 1065, 'random': 2754, 'riddle': 2887, 'diophantine': 909, 'equation': 1109, 'math': 2078, 'cardio': 499, 'surgeon': 3287, 'anil': 149, 'bhan': 352, 'senior': 2996, 'yr': 3745, 'exp': 1170, 'motivate': 2212, 'merton': 2125, 'sociologist': 3111, 'undeveloped': 3519, 'tend': 3358, 'placement': 2528, 'vlsiguru': 3601, 'earlier': 998, 'mortgage': 2206, 'potassium': 2585, 'pineapple': 2522, 'juice': 1801, 'mermaid': 2124, 'chittorgarh': 571, 'beverage': 349, 'emoticon': 1064, 'friends': 1354, 'calculate': 471, 'radius': 2744, 'mechanism': 2097, 'action': 37, 'xulane': 3731, 'contraceptive': 708, 'patch': 2459, 'ignorance': 1624, 'bliss': 390, 'lie': 1939, 'vocal': 3602, 'inch': 1654, 'erect': 1112, 'rocket': 2901, 'satellite': 2950, 'orbit': 2390, 'circle': 583, 'neutrophil': 2287, 'wbc': 3639, 'platelet': 2535, 'lymphocyte': 2014, 'infection': 1676, 'enlarged': 1090, 'salivary': 2941, 'gland': 1421, 'sore': 3133, 'throat': 3391, 'fever': 1243, 'sinnister': 3075, 'underlying': 3514, 'bharathnatyam': 353, 'annanagar': 154, 'approval': 185, 'request': 2845, 'kidnapping': 1829, 'spell': 3156, 'castrate': 510, 'penance': 2474, 'postgraduate': 2584, 'nimhans': 2304, 'hons': 1571, 'webmd': 3645, 'mayo': 2087, 'iim': 1628, 'xii': 3728, 'obc': 2341, 'shotgun': 3040, 'neb': 2271, 'board': 398, 'nepal': 2280, 'ten': 3357, 'posses': 2578, 'potential': 2586, 'dependant': 855, 'statement': 3195, 'competence': 660, 'quorreled': 2734, 'overrate': 2417, 'uninterruptible': 3525, 'mode': 2176, 'cooky': 720, 'exponential': 1183, 'frac': 1330, 'sqrt': 3172, 'courtesy': 741, 'useable': 3553, 'exit': 1169, 'kingdom': 1835, 'mnc': 2173, 'construction': 699, 'monopoly': 2194, 'spiritual': 3161, 'narcist': 2253, 'ptsd': 2694, 'coagulate': 621, 'lourdes': 1996, 'sebastin': 2979, 'french': 1347, 'justify': 1807, 'columbus': 644, 'fifa': 1252, 'imo': 1642, 'frontend': 1359, 'amp': 134, 'per': 2480, 'km': 1839, 'perpetuate': 2492, 'sexism': 3023, 'niccol': 2296, 'machiavelli': 2018, 'contributor': 713, 'renaissance': 2833, 'inferior': 1677, 'anglocentric': 147, 'frustration': 1364, 'organize': 2397, 'atheist': 234, 'knock': 1844, 'transfer': 3446, 'attorney': 243, 'element': 1051, 'atom': 236, 'mainly': 2027, 'empty': 1074, 'policeman': 2552, 'squad': 3173, 'gorgeous': 1440, 'boxer': 416, 'allen': 104, 'bet': 346, 'grade': 1447, 'playful': 2539, 'teasing': 3340, 'artificial': 216, 'island': 1757, 'manhattan': 2045, 'sehwag': 2986, 'academy': 21, 'chris': 577, 'tashima': 3330, 'downgrade': 963, 'resume': 2868, 'position': 2576, 'leadership': 1896, 'mesh': 2126, 'mist': 2169, 'eliminator': 1055, 'errand': 1116, 'vlogging': 3600, 'approximately': 188, 'intermediate': 1717, 'figure': 1255, 'skating': 3083, 'generally': 1393, 'assume': 231, 'gap': 1383, 'measure': 2095, 'pretty': 2619, 'floyd': 1290, 'legend': 1915, 'classic': 594, 'doordarshan': 960, 'ducktales': 984, 'talespin': 3322, 'jungle': 1805, 'aladdin': 93, 'onsite': 2373, 'ssd': 3179, 'esd': 1119, 'electronic': 1048, 'storage': 3219, 'quoras': 2733, 'blind': 388, 'eye': 1193, 'quorans': 2732, 'abusive': 19, 'insincere': 1695, 'seo': 3003, 'marijuana': 2059, 'illegal': 1633, 'proven': 2684, 'greed': 1462, 'misinformation': 2166, 'lift': 1945, 'rage': 2746, 'tailgate': 3320, 'cut': 792, 'knaresborough': 1840, 'england': 1087, 'mangalore': 2043, 'mysore': 2243, 'ee': 1028, 'vssut': 3614, 'global': 1422, 'counsellor': 734, 'certification': 532, 'pauline': 2462, 'donkey': 956, 'kong': 1849, 'princess': 2630, 'peach': 2472, 'crowd': 765, 'serious': 3011, 'synopsis': 3312, 'stem': 3206, 'injection': 1689, 'arthritic': 213, 'wrist': 3720, 'focus': 1293, 'procrastinate': 2646, 'ottoman': 2408, 'levant': 1927, 'arabian': 194, 'balkan': 289, 'betray': 347, 'empire': 1067, 'afford': 68, 'hashimoto': 1514, 'blame': 383, 'seizure': 2987, 'entirely': 1097, 'behaviour': 334, 'tad': 3319, 'cummins': 782, 'leniency': 1920, 'tj': 3408, 'maxx': 2085, 'attempt': 240, 'entertain': 1095, 'assure': 232, 'authentic': 258, 'assessment': 228, 'scrutiny': 2974, 'optimal': 2386, 'lonavala': 1982, 'crabbily': 745, 'hunger': 1593, 'liberals': 1935, 'reality': 2778, 'foundry': 1328, 'percent': 2481, 'abrasive': 9, 'mineral': 2156, 'classify': 596, 'biotic': 374, 'factor': 1202, 'interact': 1715, 'abiotic': 4, 'telecommunication': 3347, 'rahul': 2747, 'pretending': 2618, 'iit': 1630, 'foreigner': 1311, 'lithium': 1968, 'dioxide': 910, 'contain': 704, 'metal': 2131, 'diploblastik': 911, 'billion': 365, 'frost': 1360, 'dropper': 980, 'exactly': 1151, 'verify': 3577, 'characterize': 549, 'clair': 592, 'lune': 2009, 'natural': 2263, 'exploit': 1182, 'foster': 1324, 'trudeau': 3473, 'nationalistic': 2260, 'ideal': 1619, 'brexit': 437, 'lepen': 1921, 'microbiology': 2138, 'astoundingly': 233, 'vast': 3565, 'cleverly': 601, 'sarcastic': 2947, 'rest': 2864, 'indiaqr': 1665, 'compatible': 658, 'paytm': 2467, 'qr': 2716, 'code': 625, 'austria': 257, 'rationally': 2765, 'sensitive': 2999, 'cancel': 486, 'lost': 1989, 'fully': 1366, 'transform': 3447, 'oneself': 2370, 'putin': 2713, 'cyber': 794, 'slander': 3089, 'propagandist': 2672, 'realignment': 2777, 'essentially': 1125, 'globalism': 1424, 'taxi': 3334, 'hacked': 1491, 'marketer': 2064, 'influencer': 1681, 'abu': 17, 'dhabi': 884, 'resistor': 2856, 'transistor': 3449, 'breadboard': 427, 'statistic': 3198, 'soccer': 3108, 'tighten': 3401, 'immigration': 1641, 'resolution': 2857, 'audiology': 251, 'odds': 2354, 'desertification': 863, 'sleeveless': 3093, 'frown': 1361, 'upon': 3543, 'indonesian': 1670, 'tube': 3481, 'hippopotamus': 1552, 'gorgops': 1441, 'primate': 2627, 'non': 2310, 'ivy': 1771, 'league': 1897, 'expandable': 1171, 'dreamweaver': 973, 'band': 294, 'nightwish': 2302, 'romanian': 2907, 'indefinite': 1660, 'feminine': 1238, 'una': 3507, 'origin': 2398, 'ejaculate': 1037, 'ear': 996, 'canal': 485, 'stds': 3201, 'aid': 81, 'condom': 679, 'tigernut': 3400, 'fattening': 1221, 'fridge': 1351, 'ias': 1608, 'vellore': 3569, 'peaceful': 2471, 'unanth': 3508, 'mooc': 2200, 'provider': 2686, 'kochi': 1848, 'munnar': 2233, 'afternoon': 71, 'infect': 1675, 'chlamydia': 572, 'kissing': 1836, 'bill': 363, 'shorty': 3039, 'award': 271, 'modernize': 2181, 'theme': 3377, 'pro': 2638, 'cruise': 769, 'offer': 2357, 'freely': 1343, 'eardrum': 997, 'eligible': 1053, 'decision': 834, 'grape': 1456, 'prominent': 2668, 'flavor': 1282, 'dimetapp': 908, 'medicine': 2100, 'connect': 684, 'output': 2411, 'clickbait': 602, 'paul': 2461, 'ii': 1627, 'mistress': 2171, 'kneeler': 1841, 'elon': 1058, 'musk': 2237, 'alien': 100, 'fragment': 1331, 'cross': 763, 'lumberyard': 2007, 'myth': 2245, 'propagate': 2673, 'ffffound': 1245, 'premier': 2602, 'perform': 2485, 'competition': 661, 'subscription': 3248, 'dirty': 916, 'turkish': 3487, 'ancestry': 142, 'wife': 3680, 'vacant': 3558, 'rental': 2836, 'property': 2674, 'paranormal': 2441, 'caste': 509, 'kamma': 1811, 'velama': 3568, 'subcastes': 3242, 'cmat': 618, 'decent': 832, 'principle': 2632, 'categorize': 515, 'monitor': 2193, 'insanity': 1692, 'beyond': 350, 'waite': 3618, 'phillips': 2504, 'michael': 2136, 'wallis': 3623, 'sunburn': 3268, 'apollo': 173, 'spirulina': 3162, 'tablet': 3316, 'aim': 83, 'clothing': 613, 'designer': 866, 'sought': 3135, 'dropout': 979, 'google': 1436, 'abs': 11, 'adhesive': 50, 'punishment': 2701, 'iam': 1607, 'ubuntu': 3501, 'aws': 273, 'wake': 3620, 'dominate': 954, 'nature': 2264, 'fearless': 1229, 'francine': 1336, 'pascal': 2454, 'fetxh': 1242, 'lakh': 1868, 'danny': 808, 'wall': 3622, 'hymn': 1600, 'landed': 1870, 'immigrant': 1639, 'blue': 397, 'beer': 328, 'advertise': 62, 'mega': 2106, 'humanity': 1586, 'whistle': 3675, 'loundly': 1995, 'mosk': 2207, 'giant': 1413, 'incinerator': 1655, 'chamber': 540, 'teach': 3336, 'tokyo': 3413, 'lessen': 1924, 'frequent': 1349, 'soledad': 3115, 'colombia': 640, 'rice': 2884, 'visible': 3593, 'coaching': 620, 'ssc': 3178, 'cgl': 535, 'preparation': 2604, 'manger': 2044, 'regret': 2809, 'helpme': 1536, 'item': 1769, 'hi': 1543, 'streaming': 3226, 'mycaster': 2241, 'minimize': 2157, 'browse': 446, 'operate': 2377, 'thanks': 3375, 'kurti': 1859, 'unstitched': 3536, 'pachabottu': 2421, 'workout': 3711, 'skilled': 3085, 'amanda': 120, 'rodgers': 2902, 'sensationalism': 2997, 'propaganda': 2671, 'facing': 1200, 'degrading': 841, 'insult': 1708, 'grammar': 1451, 'obsess': 2346, 'overweight': 2419, 'misfit': 2165, 'homeschooled': 1565, 'bimbo': 368, 'parallel': 2440, 'revenue': 2874, 'commission': 650, 'hollywood': 1561, 'theatre': 3376, 'linguistics': 1957, 'facet': 1198, 'armenian': 201, 'georgian': 1404, 'azerbaijanis': 274, 'genetically': 1397, 'cla': 590, 'grand': 1452, 'coulee': 733, 'dam': 804, 'stan': 3186, 'lee': 1908, 'urinate': 3546, 'obsessed': 2347, 'statue': 3199, 'side': 3049, 'smile': 3100, 'racist': 2741, 'irish': 1749, 'remainder': 2828, 'planet': 2532, 'modify': 2183, 'kitchen': 1837, 'vent': 3574, 'stove': 3222, 'odor': 2355, 'wo': 3697, 'apartment': 172, 'batra': 315, 'ludhiana': 2005, 'nehru': 2276, 'pimp': 2520, 'elasticity': 1039, 'studio': 3237, 'simple': 3064, 'laruelle': 1878, 'morgan': 2203, 'freeman': 1344, 'considerd': 692, 'homosexual': 1568, 'torrent': 3427, 'quick': 2727, 'egregious': 1034, 'cruelty': 768, 'cruel': 767, 'perhaps': 2489, 'racially': 2739, 'svce': 3296, 'tamil': 3325, 'teaching': 3338, 'bhagat': 351, 'vita': 3597, 'functioning': 1370, 'yiddish': 3739, 'khazari': 1825, 'jewish': 1786, 'secret': 2981, 'behind': 335, 'porsche': 2572, 'pdk': 2470, 'release': 2823, 'dysfuntional': 995, 'thailand': 3373, 'langan': 1871, 'ctmu': 775, 'sooner': 3132, 'cable': 468, 'sterilize': 3209, 'electricity': 1045, 'indians': 1664, 'susceptible': 3293, 'alcohol': 95, 'marcos': 2057, 'identical': 1620, 'twin': 3492, 'young': 3743, 'deceased': 831, 'share': 3028, 'probate': 2639, 'sindhi': 3069, 'btu': 448, 'pit': 2525, 'nit': 2306, 'surathkal': 3283, 'friendship': 1355, 'smok': 3102, 'vape': 3561, 'muscular': 2235, 'tension': 3361, 'nourish': 2322, 'tissue': 3407, 'attraction': 245, 'offline': 2360, 'gif': 1415, 'tenor': 3359, 'keyboard': 1823, '': 3749, 'pinyin': 2523, 'xixie': 3729, 'lilo': 1973, 'aptitude': 191, 'center': 525, 'coimbatore': 630, 'trolling': 3469, 'bromelain': 444, 'curcumin': 783, 'bioavailability': 369, 'scenario': 2961, 'trevor': 3462, 'vibrate': 3583, 'tense': 3360, 'bid': 358, 'al': 92, 'capone': 491, 'recent': 2786, 'auction': 247, 'fondness': 1300, 'proponent': 2675, 'nouveau': 2323, 'erythromycin': 1117, 'acne': 34, 'minoxidil': 2163, 'beard': 323, 'approximate': 187, 'trip': 3467, 'manchester': 2038, 'oman': 2368, 'elimination': 1054, 'airline': 88, 'minimum': 2158, 'frozen': 1362, 'easa': 1004, 'atpl': 237, 'steven': 3210, 'spielberg': 3159, 'underrated': 3516, 'tulu': 3483, 'nokia': 2308, 'deport': 857, 'ambassador': 125, 'monthly': 2197, 'bran': 422, 'district': 938, 'caa': 467, 'kapil': 1812, 'dev': 875, 'semen': 2992, 'initial': 1687, 'ngo': 2295, 'decrease': 836, 'gym': 1488, 'dalit': 803, 'oher': 2362, 'repay': 2837, 'viteee': 3599, 'ece': 1013, 'specialisation': 3150, 'realize': 2779, 'poetical': 2547, 'biotechnology': 373, 'sow': 3141, 'stabilizer': 3181, 'ton': 3417, 'gts': 1473, 'hotel': 1576, 'havelock': 1518, 'severely': 3019, 'depressed': 858, 'fiance': 1246, 'self': 2990, 'evidence': 1146, 'simply': 3066, 'hearsay': 1526, 'imprisonment': 1650, 'hillary': 1549, 'clinton': 605, 'uniform': 3524, 'terrible': 3364, 'un': 3506, 'assembly': 227, 'kazeroon': 1815, 'epoch': 1106, 'suck': 3254, 'severus': 3020, 'snape': 3106, 'concoct': 677, 'potion': 2587, 'alzheimer': 118, 'diagnose': 886, 'frightened': 1358, 'liquids': 1961, 'nutritious': 2336, 'substantial': 3250, 'jadavpur': 1772, 'spot': 3168, 'round': 2915, 'manager': 2037, 'club': 616, 'promote': 2669, 'kenyan': 1821, 'polite': 2554, 'courteous': 740, 'disaster': 922, 'nuke': 2332, 'investor': 1739, 'shy': 3046, 'struggle': 3234, 'halfway': 1495, 'scared': 2958, 'allows': 108, 'moron': 2205, 'supporter': 3280, 'lesson': 1925, 'stupid': 3239, 'bound': 413, 'engel': 1083, 'vitale': 3598, 'absorbed': 16, 'freinds': 1346, 'scratch': 2971, 'influential': 1682, 'vendor': 3571, 'reject': 2815, 'slatwall': 3090, 'bhopal': 355, 'draft': 965, 'dogme': 949, 'daddy': 800, 'quantico': 2719, 'americans': 129, 'southern': 3139, 'whine': 3674, 'jim': 1789, 'crow': 764, 'appreciator': 182, 'waitlist': 3619, 'sls': 3096, 'belong': 340, 'luxury': 2012, 'lifestyle': 1943, 'vomit': 3608, 'warangal': 3629, 'map': 2054, 'problen': 2641, 'ant': 163, 'leftover': 1911, 'babe': 276, 'ruth': 2928, 'digit': 903, 'seven': 3017, 'mofo': 2184, 'objectionable': 2343, 'fancy': 1214, 'investigator': 1737, 'client': 603, 'universal': 3529, 'java': 1778, 'caption': 494, 'insta': 1697, 'disgust': 928, 'unwatermarking': 3540, 'japan': 1775, 'invade': 1731, 'six': 3081, 'cherry': 559, 'blossom': 395, 'alicia': 99, 'purely': 2707, 'salarie': 2936, 'simplify': 3065, 'shopping': 3036, 'sikkim': 3057, 'filmora': 1261, 'adobe': 55, 'premiere': 2603, 'pencil': 2475, 'digital': 904, 'canvas': 490, 'ernest': 1114, 'dwarf': 993, 'fortress': 1321, 'stoicism': 3217, 'inxj': 1742, 'intj': 1724, 'infj': 1679, 'stoic': 3216, 'pore': 2569, 'tough': 3429, 'breakup': 431, 'existence': 1168, 'energetic': 1081, 'pwd': 2714, 'merit': 2123, 'navy': 2266, 'technical': 3341, 'ssb': 3177, 'brace': 419, 'campco': 481, 'chocolate': 573, 'weak': 3641, 'unconditionally': 3510, 'edward': 1027, 'snowden': 3107, 'traitor': 3443, 'hero': 1541, 'soil': 3113, 'erosion': 1115, 'ahmedabad': 79, 'labour': 1862, 'central': 526, 'oscar': 2402, 'equality': 1108, 'bouble': 412, 'tuba': 3480, 'transposition': 3454, 'xxl': 3732, 'panda': 2434, 'reinforcement': 2813, 'dome': 952, 'bravery': 425, 'winner': 3685}\n"
     ]
    }
   ],
   "source": [
    "# You can use the below syntax to see the vocabulary that \n",
    "# it has learned from the corpus\n",
    "print(Tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2984)\t0.359822804791192\n",
      "  (0, 2722)\t0.4769778638491273\n",
      "  (0, 2687)\t0.4769778638491273\n",
      "  (0, 2259)\t0.4769778638491273\n",
      "  (0, 2256)\t0.43359416664199923\n",
      "  (1, 3716)\t0.2211970537062105\n",
      "  (1, 3035)\t0.3979098519972901\n",
      "  (1, 2479)\t0.2137842082034569\n",
      "  (1, 1076)\t0.3979098519972901\n",
      "  (1, 948)\t0.3138745442899514\n",
      "  (1, 56)\t0.700133162739973\n",
      "  (2, 3570)\t0.6684416456097466\n",
      "  (2, 3402)\t0.2074585305121635\n",
      "  (2, 3144)\t0.2940352953682655\n",
      "  (2, 1402)\t0.3342208228048733\n",
      "  (2, 67)\t0.5585574377032303\n",
      "  (3, 3609)\t0.43300022699063984\n",
      "  (3, 3552)\t0.2501080109278229\n",
      "  (3, 2407)\t0.43300022699063984\n",
      "  (3, 2021)\t0.43300022699063984\n",
      "  (3, 1537)\t0.43300022699063984\n",
      "  (3, 1475)\t0.43300022699063984\n",
      "  (4, 3499)\t0.4150402905595966\n",
      "  (4, 2216)\t0.3929578728434521\n",
      "  (4, 2198)\t0.4150402905595966\n",
      "  :\t:\n",
      "  (1494, 3716)\t0.3432699914794571\n",
      "  (1494, 2034)\t0.4956311219272528\n",
      "  (1494, 814)\t0.5051750423988072\n",
      "  (1495, 2434)\t0.6166576437333342\n",
      "  (1495, 2225)\t0.3827735433249775\n",
      "  (1495, 729)\t0.4864245907413059\n",
      "  (1495, 569)\t0.4864245907413059\n",
      "  (1496, 2872)\t0.415171860938022\n",
      "  (1496, 2431)\t0.7972368731575123\n",
      "  (1496, 1662)\t0.26907755771459163\n",
      "  (1496, 280)\t0.3458944375060736\n",
      "  (1497, 3638)\t0.3790095908130043\n",
      "  (1497, 1899)\t0.44237673668980587\n",
      "  (1497, 1291)\t0.5707487686680138\n",
      "  (1497, 1088)\t0.4802365721625535\n",
      "  (1497, 345)\t0.3229136583189752\n",
      "  (1498, 2813)\t0.5742922134883773\n",
      "  (1498, 1409)\t0.291732895910009\n",
      "  (1498, 952)\t0.5742922134883773\n",
      "  (1498, 865)\t0.5052413527188763\n",
      "  (1499, 3736)\t0.31114173266940054\n",
      "  (1499, 3685)\t0.5012570254159971\n",
      "  (1499, 3221)\t0.4188560685678199\n",
      "  (1499, 425)\t0.5012570254159971\n",
      "  (1499, 271)\t0.4745874049715245\n"
     ]
    }
   ],
   "source": [
    "print(Train_X_Tfidf)\n",
    "\n",
    "# Output: \n",
    "# 1: Row number of Train_X_Tfidf, \n",
    "# 2: Unique Integer number of each word, \n",
    "# 3: Score calculated by TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3701)\t0.3734896098102999\n",
      "  (0, 2591)\t0.44407671410999455\n",
      "  (0, 2052)\t0.3734896098102999\n",
      "  (0, 1969)\t0.56297174397079\n",
      "  (0, 1409)\t0.28598224619221757\n",
      "  (0, 326)\t0.3536719738205323\n",
      "  (1, 3281)\t0.266996897191993\n",
      "  (1, 2867)\t0.533993794383986\n",
      "  (1, 1086)\t0.4448892146082996\n",
      "  (1, 647)\t0.282000889782967\n",
      "  (1, 639)\t0.41010481106819174\n",
      "  (1, 181)\t0.4448892146082996\n",
      "  (2, 2780)\t0.7966406205496306\n",
      "  (2, 1948)\t0.6044532419387785\n",
      "  (3, 1098)\t1.0\n",
      "  (4, 2780)\t0.507805290077353\n",
      "  (4, 2479)\t0.37088975598639595\n",
      "  (4, 2032)\t0.4024411538554405\n",
      "  (4, 1435)\t0.38222767221616827\n",
      "  (4, 1025)\t0.5445343887666951\n",
      "  (5, 3441)\t0.5278840483427031\n",
      "  (5, 2995)\t0.552242715389823\n",
      "  (5, 2129)\t0.645264608361712\n",
      "  (6, 785)\t1.0\n",
      "  (7, 2801)\t0.5670793676000434\n",
      "  :\t:\n",
      "  (96, 3638)\t0.23352200096193673\n",
      "  (96, 3383)\t0.2276808310607928\n",
      "  (96, 3192)\t0.5257329844491245\n",
      "  (96, 3014)\t0.3051467741065897\n",
      "  (96, 2372)\t0.3003086217111001\n",
      "  (96, 1816)\t0.31049510344839204\n",
      "  (96, 1204)\t0.3403324352703592\n",
      "  (96, 978)\t0.36626305695604744\n",
      "  (96, 463)\t0.2958917346285084\n",
      "  (97, 1662)\t0.41343547952036563\n",
      "  (97, 738)\t0.612473986579742\n",
      "  (97, 304)\t0.6737556827492317\n",
      "  (98, 3552)\t0.34802045180270264\n",
      "  (98, 2692)\t0.5477097785579431\n",
      "  (98, 1375)\t0.5034653977586614\n",
      "  (98, 842)\t0.5704545177827628\n",
      "  (99, 3610)\t0.3865340870625948\n",
      "  (99, 3475)\t0.30580134902938183\n",
      "  (99, 3410)\t0.3252355768162791\n",
      "  (99, 3080)\t0.3865340870625948\n",
      "  (99, 1845)\t0.27228038533811666\n",
      "  (99, 1429)\t0.2687919802087058\n",
      "  (99, 383)\t0.40258568474428996\n",
      "  (99, 285)\t0.30918397913458395\n",
      "  (99, 128)\t0.31278499037398094\n"
     ]
    }
   ],
   "source": [
    "print(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "train_Y = train[\"target\"]\n",
    "\n",
    "Naive.fit(Train_X_Tfidf,train_Y)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "print(predictions_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "\n",
    "SVM.fit(Train_X_Tfidf,train['target'])\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "print(predictions_SVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
